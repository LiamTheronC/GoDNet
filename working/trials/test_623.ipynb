{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to figure out M6 post and to_world.\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from fractions import gcd\n",
    "from numbers import Number\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from utils import collate_fn,gpu,to_long\n",
    "import logging\n",
    "from memory_profiler import profile\n",
    "import gc\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import copy\n",
    "import torch\n",
    "from utils import poly_gon_and_line,bboxes_overlapping,bboxes_of_poly, to_local\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# config = dict()\n",
    "# config['pred_range'] = [-100.0, 100.0, -100.0, 100.0]\n",
    "# config['num_scales'] = 6\n",
    "# config['cross_dist'] = 6\n",
    "# config['downsample_factor'] = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/avt/prediction/Waymo/data_processed/xy/train_1f/0_1.pt'\n",
    "qq = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-17.46998,  -6.6051 ], dtype=float32),\n",
       " array([ 3.2306695, -6.6977224], dtype=float32),\n",
       " array([-41.98765  ,  -7.1655674], dtype=float32),\n",
       " array([36.934135  ,  0.26777548], dtype=float32),\n",
       " array([51.291374 , -6.1735506], dtype=float32),\n",
       " array([28.55538  , -6.9359818], dtype=float32),\n",
       " array([-60.84234 ,  -7.364299], dtype=float32),\n",
       " array([44.16571  , -2.5301824], dtype=float32),\n",
       " array([51.184696 ,  3.6281319], dtype=float32),\n",
       " array([-76.826035 ,   7.6535335], dtype=float32),\n",
       " array([ 2.69516 , 46.879154], dtype=float32),\n",
       " array([-10.652971, -64.243614], dtype=float32),\n",
       " array([20.516815, 67.852806], dtype=float32),\n",
       " array([73.94654  , -1.8349819], dtype=float32),\n",
       " array([32.333256, 51.7348  ], dtype=float32),\n",
       " array([51.582195, 49.799484], dtype=float32),\n",
       " array([51.630135 ,  6.0807333], dtype=float32),\n",
       " array([0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq['ctrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq['graph']['left']['u'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_numpy(data):\n",
    "    \"\"\"Recursively transform numpy.ndarray to torch.Tensor.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key in data.keys():\n",
    "            data[key] = from_numpy(data[key])\n",
    "    if isinstance(data, list) or isinstance(data, tuple):\n",
    "        data = [from_numpy(x) for x in data]\n",
    "    if isinstance(data, np.ndarray):\n",
    "        \"\"\"Pytorch now has bool type.\"\"\"\n",
    "        data = torch.from_numpy(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/avt/prediction/Waymo/working/')\n",
    "\n",
    "from fractions import gcd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from typing import Dict, List, Tuple, Union\n",
    "from utils import to_long, gpu\n",
    "\n",
    "# config[\"dim_feats\"] = {'xyvp':[6,2], 'xyz':[4,3], 'xy':[3,2],  'xyp':[4,2]}\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_in, n_out, norm='GN', ng=32, act=True):\n",
    "        super(Linear, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.linear = nn.Linear(n_in, n_out, bias=False)\n",
    "        \n",
    "        if norm == 'GN':\n",
    "            self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.norm(out)\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class LinearRes(nn.Module):\n",
    "    def __init__(self, n_in, n_out, norm='GN', ng=32):\n",
    "        super(LinearRes, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.linear1 = nn.Linear(n_in, n_out, bias=False)\n",
    "        self.linear2 = nn.Linear(n_out, n_out, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if norm == 'GN':\n",
    "            self.norm1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "            self.norm2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm1 = nn.BatchNorm1d(n_out)\n",
    "            self.norm2 = nn.BatchNorm1d(n_out)\n",
    "        else:   \n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        if n_in != n_out:\n",
    "            if norm == 'GN':\n",
    "                self.transform = nn.Sequential(\n",
    "                    nn.Linear(n_in, n_out, bias=False),\n",
    "                    nn.GroupNorm(gcd(ng, n_out), n_out))\n",
    "            elif norm == 'BN':\n",
    "                self.transform = nn.Sequential(\n",
    "                    nn.Linear(n_in, n_out, bias=False),\n",
    "                    nn.BatchNorm1d(n_out))\n",
    "            else:\n",
    "                exit('SyncBN has not been added!')\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.norm2(out)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            out += self.transform(x)\n",
    "            \n",
    "        else:\n",
    "            out += x\n",
    "        out = self.relu(out) \n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Conv1d(nn.Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, norm='GN', ng=32, act=True):\n",
    "        super(Conv1d, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.conv = nn.Conv1d(n_in, n_out, kernel_size=kernel_size, padding=(int(kernel_size) - 1) // 2, stride=stride, bias=False)\n",
    "\n",
    "        if norm == 'GN':\n",
    "            self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.norm(out)\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    " \n",
    "\n",
    "class Res1d(nn.Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, norm='GN', ng=32, act=True):\n",
    "        super(Res1d, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "        padding = (int(kernel_size) - 1) // 2\n",
    "        self.conv1 = nn.Conv1d(n_in, n_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.conv2 = nn.Conv1d(n_out, n_out, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        # All use name bn1 and bn2 to load imagenet pretrained weights\n",
    "        if norm == 'GN':\n",
    "            self.bn1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "            self.bn2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.bn1 = nn.BatchNorm1d(n_out)\n",
    "            self.bn2 = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        if stride != 1 or n_out != n_in:\n",
    "            if norm == 'GN':\n",
    "                self.downsample = nn.Sequential(\n",
    "                        nn.Conv1d(n_in, n_out, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.GroupNorm(gcd(ng, n_out), n_out))\n",
    "            elif norm == 'BN':\n",
    "                self.downsample = nn.Sequential(\n",
    "                        nn.Conv1d(n_in, n_out, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.BatchNorm1d(n_out))\n",
    "            else:\n",
    "                exit('SyncBN has not been added!')\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        out += x\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def actor_gather(actors: List[Tensor]) -> Tuple[Tensor, List[Tensor]]:\n",
    "    \"\"\"\n",
    "    actors is data['feat']\n",
    "     \n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(actors)\n",
    "    num_actors = [len(x) for x in actors]\n",
    "\n",
    "    actors = [torch.stack(x).transpose(1, 2) for x in actors]\n",
    "    actors = torch.cat(actors, 0)\n",
    "\n",
    "    actor_idcs = []\n",
    "    count = 0\n",
    "    for i in range(batch_size):\n",
    "        idcs = torch.arange(count, count + num_actors[i]).to(actors.device)\n",
    "        actor_idcs.append(idcs)\n",
    "        count += num_actors[i]\n",
    "    return actors, actor_idcs\n",
    "\n",
    "\n",
    "def graph_gather(graphs):\n",
    "    batch_size = len(graphs)\n",
    "    node_idcs = []\n",
    "    count = 0\n",
    "    counts = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        counts.append(count)\n",
    "        idcs = torch.arange(count, count + graphs[i][\"num_nodes\"])\n",
    "        node_idcs.append(idcs)\n",
    "        count = count + graphs[i][\"num_nodes\"]\n",
    "\n",
    "    graph = dict()\n",
    "    graph[\"idcs\"] = node_idcs\n",
    "    graph[\"ctrs\"] = [x[\"ctrs\"] for x in graphs]\n",
    "\n",
    "    graph['feats'] = torch.cat([x['feats'] for x in graphs], 0)\n",
    "\n",
    "    for k1 in [\"pre\", \"suc\"]:\n",
    "        graph[k1] = []\n",
    "        for i in range(len(graphs[0][\"pre\"])):\n",
    "            graph[k1].append(dict())\n",
    "            for k2 in [\"u\", \"v\"]:\n",
    "                graph[k1][i][k2] = torch.cat(\n",
    "                    [graphs[j][k1][i][k2] + counts[j] for j in range(batch_size)], 0\n",
    "                )\n",
    "\n",
    "    for k1 in [\"left\", \"right\"]:\n",
    "        graph[k1] = dict()\n",
    "        for k2 in [\"u\", \"v\"]:\n",
    "            temp = [graphs[i][k1][k2] + counts[i] for i in range(batch_size)]\n",
    "            temp = [\n",
    "                x if x.dim() > 0 else graph[\"pre\"][0][\"u\"].new().resize_(0)\n",
    "                for x in temp\n",
    "            ]\n",
    "            graph[k1][k2] = torch.cat(temp)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n",
    "class ActorNet(nn.Module):\n",
    "    def __init__(self,config) -> None:\n",
    "        super(ActorNet,self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_in = config['dim_feats'][config['type_feats']][0]\n",
    "        n_out = [32, 64, 128]\n",
    "        blocks = [Res1d, Res1d, Res1d]\n",
    "        num_blocks = [2, 2, 2]\n",
    "\n",
    "        groups = []\n",
    "\n",
    "        for i in range(len(num_blocks)):\n",
    "\n",
    "            group = []\n",
    "\n",
    "            if i == 0:\n",
    "                group.append(blocks[i](n_in, n_out[i], norm=norm, ng=ng))\n",
    "            else:\n",
    "                group.append(blocks[i](n_in, n_out[i], stride=2, norm=norm, ng=ng))\n",
    "\n",
    "            for j in range(1, num_blocks[i]):\n",
    "                group.append(blocks[i](n_out[i], n_out[i], norm=norm, ng=ng))\n",
    "            \n",
    "            groups.append(nn.Sequential(*group))\n",
    "            \n",
    "            n_in = n_out[i]\n",
    "\n",
    "        self.groups = nn.ModuleList(groups)\n",
    "\n",
    "        n = config['n_actornet']#128\n",
    "        \n",
    "        lateral = []\n",
    "        for i in range(len(n_out)):\n",
    "            lateral.append(Conv1d(n_out[i], n, norm=norm, ng=ng, act=False))\n",
    "        self.lateral = nn.ModuleList(lateral)\n",
    "\n",
    "        self.outlayer = Res1d(n, n, norm=norm, ng=ng)\n",
    "\n",
    "    def forward(self, actors: Tensor) -> Tensor:\n",
    "        #actors [batch_size,feature_dim(),time_step(11)]\n",
    "        \n",
    "        out = actors\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(len(self.groups)):\n",
    "            out = self.groups[i](out)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        out = self.lateral[-1](outputs[-1])\n",
    "\n",
    "        for i in range(len(outputs) - 2, -1, -1):\n",
    "\n",
    "            out = F.interpolate(out, scale_factor=2, mode=\"linear\", align_corners=False)\n",
    "            tmp = self.lateral[i](outputs[i])\n",
    "\n",
    "            if out.shape != tmp.shape:\n",
    "                out = out[:,:,:tmp.shape[2]]\n",
    "\n",
    "            out += tmp\n",
    "        \n",
    "        out = self.outlayer(out)[:,:,-1]\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MapNet(nn.Module):\n",
    "  \n",
    "    def __init__(self, config):\n",
    "        super(MapNet, self).__init__()\n",
    "        self.config = config\n",
    "        n_map = 128\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "        n_in = config['dim_feats'][config['type_feats']][1]\n",
    "\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Linear(n_in, n_map),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_map, n_map, norm=norm, ng=ng, act=False),\n",
    "        )\n",
    "        self.seg = nn.Sequential(\n",
    "            nn.Linear(n_in, n_map),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_map, n_map, norm=norm, ng=ng, act=False),\n",
    "        )\n",
    "\n",
    "        keys = [\"ctr\", \"norm\", \"ctr2\", \"left\", \"right\"]\n",
    "        for i in range(config[\"num_scales\"]):\n",
    "            keys.append(\"pre\" + str(i))\n",
    "            keys.append(\"suc\" + str(i))\n",
    "\n",
    "        fuse = dict()\n",
    "        for key in keys:\n",
    "            fuse[key] = []\n",
    "\n",
    "        for i in range(4):\n",
    "            for key in fuse:\n",
    "                if key in [\"norm\"]:\n",
    "                    fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
    "                elif key in [\"ctr2\"]:\n",
    "                    fuse[key].append(Linear(n_map, n_map, norm=norm, ng=ng, act=False))\n",
    "                else:\n",
    "                    fuse[key].append(nn.Linear(n_map, n_map, bias=False))\n",
    "\n",
    "        for key in fuse:\n",
    "            fuse[key] = nn.ModuleList(fuse[key])\n",
    "        self.fuse = nn.ModuleDict(fuse)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        if (\n",
    "            len(graph[\"feats\"]) == 0\n",
    "            or len(graph[\"pre\"][-1][\"u\"]) == 0\n",
    "            or len(graph[\"suc\"][-1][\"u\"]) == 0\n",
    "        ):\n",
    "            temp = graph[\"feats\"]\n",
    "            return (\n",
    "                temp.new().resize_(0),\n",
    "                [temp.new().long().resize_(0) for x in graph[\"node_idcs\"]],\n",
    "                temp.new().resize_(0),\n",
    "            )\n",
    "\n",
    "        ctrs = torch.cat(graph[\"ctrs\"], 0)\n",
    "        feat = self.input(ctrs)\n",
    "        feat += self.seg(graph[\"feats\"])\n",
    "        feat = self.relu(feat)\n",
    "\n",
    "        \"\"\"fuse map\"\"\"\n",
    "        res = feat\n",
    "        for i in range(len(self.fuse[\"ctr\"])):\n",
    "            temp = self.fuse[\"ctr\"][i](feat)\n",
    "            for key in self.fuse:\n",
    "                if key.startswith(\"pre\") or key.startswith(\"suc\"):\n",
    "                    k1 = key[:3]\n",
    "                    k2 = int(key[3:])\n",
    "                    temp.index_add_(\n",
    "                        0,\n",
    "                        graph[k1][k2][\"u\"],\n",
    "                        self.fuse[key][i](feat[graph[k1][k2][\"v\"]]),\n",
    "                    )\n",
    "\n",
    "            if len(graph[\"left\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"left\"][\"u\"],\n",
    "                    self.fuse[\"left\"][i](feat[graph[\"left\"][\"v\"]]),\n",
    "                )\n",
    "            if len(graph[\"right\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"right\"][\"u\"],\n",
    "                    self.fuse[\"right\"][i](feat[graph[\"right\"][\"v\"]]),\n",
    "                )\n",
    "\n",
    "            feat = self.fuse[\"norm\"][i](temp)\n",
    "            feat = self.relu(feat)\n",
    "\n",
    "            feat = self.fuse[\"ctr2\"][i](feat)\n",
    "            feat += res\n",
    "            feat = self.relu(feat)\n",
    "            res = feat\n",
    "\n",
    "        return feat , graph[\"idcs\"], graph[\"ctrs\"]\n",
    "\n",
    "\n",
    "class Att(nn.Module):\n",
    "    def __init__(self, n_agt: int, n_ctx: int, config) -> None:\n",
    "        super(Att, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "        n_in = config['dim_feats'][config['type_feats']][1]\n",
    "\n",
    "        self.dist = nn.Sequential(\n",
    "            nn.Linear(n_in, n_ctx),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_ctx, n_ctx, norm=norm, ng=ng),\n",
    "        )\n",
    "\n",
    "        self.query = Linear(n_agt, n_ctx, norm=norm, ng=ng)\n",
    "\n",
    "        self.ctx = nn.Sequential(\n",
    "            Linear(3 * n_ctx, n_agt, norm=norm, ng=ng),\n",
    "            nn.Linear(n_agt, n_agt, bias=False),\n",
    "        )\n",
    "\n",
    "        self.agt = nn.Linear(n_agt, n_agt, bias=False)\n",
    "        self.norm = nn.GroupNorm(gcd(ng, n_agt), n_agt)\n",
    "        self.linear = Linear(n_agt, n_agt, norm=norm, ng=ng, act=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, agts: Tensor, agt_idcs: List[Tensor], agt_ctrs: List[Tensor], ctx: Tensor, ctx_idcs: List[Tensor], ctx_ctrs: List[Tensor], dist_th: float) -> Tensor:\n",
    "        # feat, graph[\"idcs\"], graph[\"ctrs\"], actors, actor_idcs, actor_ctrs, config[\"actor2map_dist\"]      \n",
    "        res = agts\n",
    "        if len(ctx) == 0:\n",
    "            agts = self.agt(agts)\n",
    "            agts = self.relu(agts)\n",
    "            agts = self.linear(agts)\n",
    "            agts += res\n",
    "            agts = self.relu(agts)\n",
    "            return agts\n",
    "\n",
    "        batch_size = len(agt_idcs)\n",
    "        hi, wi = [], []\n",
    "        hi_count, wi_count = 0, 0\n",
    "        n_c = self.config['dim_feats'][self.config['type_feats']][1]\n",
    "\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "        \n",
    "            dist = agt_ctrs[i].view(-1, 1, n_c) - ctx_ctrs[i].view(1, -1, n_c)\n",
    "            dist = torch.sqrt((dist ** 2).sum(2))\n",
    "            mask = dist <= dist_th\n",
    "\n",
    "            idcs = torch.nonzero(mask, as_tuple=False)\n",
    "            if len(idcs) == 0:\n",
    "                continue\n",
    "\n",
    "            hi.append(idcs[:, 0] + hi_count)\n",
    "            wi.append(idcs[:, 1] + wi_count)\n",
    "            hi_count += len(agt_idcs[i])\n",
    "            wi_count += len(ctx_idcs[i])\n",
    "\n",
    "        if hi == []:\n",
    "            print('WARNING!!! - Attention')\n",
    "\n",
    "        hi = torch.cat(hi, 0)\n",
    "        wi = torch.cat(wi, 0)\n",
    "\n",
    "        agt_ctrs = torch.cat(agt_ctrs, 0)\n",
    "        ctx_ctrs = torch.cat(ctx_ctrs, 0)\n",
    "        dist = agt_ctrs[hi] - ctx_ctrs[wi]\n",
    "        dist = self.dist(dist)\n",
    "\n",
    "        query = self.query(agts[hi])\n",
    "\n",
    "        ctx = ctx[wi]\n",
    "        ctx = torch.cat((dist, query, ctx), 1)\n",
    "        ctx = self.ctx(ctx)\n",
    "\n",
    "        agts = self.agt(agts)\n",
    "        agts.index_add_(0, hi, ctx)\n",
    "        agts = self.norm(agts)\n",
    "        agts = self.relu(agts)\n",
    "\n",
    "        agts = self.linear(agts)\n",
    "        agts += res\n",
    "        agts = self.relu(agts)\n",
    "\n",
    "        return agts\n",
    "\n",
    "\n",
    "class A2M(nn.Module):\n",
    "    \"\"\"\n",
    "    Actor to Map Fusion:  fuses real-time traffic information from\n",
    "    actor nodes to lane nodes\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(A2M, self).__init__()\n",
    "        self.config = config\n",
    "        n_map = config[\"n_map\"]\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        \"\"\"fuse meta, static, dyn\"\"\"\n",
    "        self.meta = Linear(n_map, n_map, norm=norm, ng=ng)\n",
    "        att = []\n",
    "        for i in range(2):\n",
    "            att.append(Att(n_map, config[\"n_actor\"], config))\n",
    "        self.att = nn.ModuleList(att)\n",
    "\n",
    "    def forward(self, feat: Tensor, graph: Dict[str, Union[List[Tensor], Tensor, List[Dict[str, Tensor]], Dict[str, Tensor]]], actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor]) -> Tensor:\n",
    "        \"\"\"meta, static and dyn fuse using attention\"\"\"\n",
    "        \n",
    "        feat = self.meta(feat)\n",
    "\n",
    "        for i in range(len(self.att)):\n",
    "            feat = self.att[i](\n",
    "                feat,\n",
    "                graph[\"idcs\"],\n",
    "                graph[\"ctrs\"],\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                self.config[\"actor2map_dist\"],\n",
    "            )\n",
    "        return feat\n",
    "\n",
    "\n",
    "class M2M(nn.Module):\n",
    " \n",
    "    def __init__(self, config):\n",
    "        super(M2M, self).__init__()\n",
    "        self.config = config\n",
    "        n_map = config[\"n_map\"]\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        keys = [\"ctr\", \"norm\", \"ctr2\", \"left\", \"right\"]\n",
    "        for i in range(config[\"num_scales\"]):\n",
    "            keys.append(\"pre\" + str(i))\n",
    "            keys.append(\"suc\" + str(i))\n",
    "\n",
    "        fuse = dict()\n",
    "        for key in keys:\n",
    "            fuse[key] = []\n",
    "\n",
    "        for i in range(4):\n",
    "            for key in fuse:\n",
    "                if key in [\"norm\"]:\n",
    "                    fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
    "                elif key in [\"ctr2\"]:\n",
    "                    fuse[key].append(Linear(n_map, n_map, norm=norm, ng=ng, act=False))\n",
    "                else:\n",
    "                    fuse[key].append(nn.Linear(n_map, n_map, bias=False))\n",
    "\n",
    "        for key in fuse:\n",
    "            fuse[key] = nn.ModuleList(fuse[key])\n",
    "        self.fuse = nn.ModuleDict(fuse)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, feat: Tensor, graph: Dict) -> Tensor:\n",
    "        \"\"\"fuse map\"\"\"\n",
    "        res = feat\n",
    "        for i in range(len(self.fuse[\"ctr\"])):\n",
    "            temp = self.fuse[\"ctr\"][i](feat)\n",
    "            for key in self.fuse:\n",
    "                if key.startswith(\"pre\") or key.startswith(\"suc\"):\n",
    "                    k1 = key[:3]\n",
    "                    k2 = int(key[3:])\n",
    "                    temp.index_add_(\n",
    "                        0,\n",
    "                        graph[k1][k2][\"u\"],\n",
    "                        self.fuse[key][i](feat[graph[k1][k2][\"v\"]]),\n",
    "                    )\n",
    "\n",
    "            if len(graph[\"left\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"left\"][\"u\"],\n",
    "                    self.fuse[\"left\"][i](feat[graph[\"left\"][\"v\"]]),\n",
    "                )\n",
    "            if len(graph[\"right\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"right\"][\"u\"],\n",
    "                    self.fuse[\"right\"][i](feat[graph[\"right\"][\"v\"]]),\n",
    "                )\n",
    "\n",
    "            feat = self.fuse[\"norm\"][i](temp)\n",
    "            feat = self.relu(feat)\n",
    "\n",
    "            feat = self.fuse[\"ctr2\"][i](feat)\n",
    "            feat += res\n",
    "            feat = self.relu(feat)\n",
    "            res = feat\n",
    "        return feat\n",
    "\n",
    "\n",
    "class M2A(nn.Module):\n",
    "    \"\"\"\n",
    "    The lane to actor block fuses updated\n",
    "        map information from lane nodes to actor nodes\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(M2A, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_actor = config[\"n_actor\"]\n",
    "        n_map = config[\"n_map\"]\n",
    "\n",
    "        att = []\n",
    "        for i in range(2):\n",
    "            att.append(Att(n_actor, n_map, config))\n",
    "        self.att = nn.ModuleList(att)\n",
    "\n",
    "    def forward(self, actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor], nodes: Tensor, node_idcs: List[Tensor], node_ctrs: List[Tensor]) -> Tensor:\n",
    "        for i in range(len(self.att)):\n",
    "            actors = self.att[i](\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                nodes,\n",
    "                node_idcs,\n",
    "                node_ctrs,\n",
    "                self.config[\"map2actor_dist\"],\n",
    "            )\n",
    "        return actors\n",
    "\n",
    "\n",
    "class A2A(nn.Module):\n",
    "    \"\"\"\n",
    "    The actor to actor block performs interactions among actors.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(A2A, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_actor = config[\"n_actor\"]\n",
    "        n_map = config[\"n_map\"]\n",
    "\n",
    "        att = []\n",
    "        for i in range(2):\n",
    "            att.append(Att(n_actor, n_actor, config))\n",
    "        self.att = nn.ModuleList(att)\n",
    "\n",
    "    def forward(self, actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor]) -> Tensor:\n",
    "        for i in range(len(self.att)):\n",
    "            actors = self.att[i](\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                self.config[\"actor2actor_dist\"],\n",
    "            )\n",
    "        return actors\n",
    "\n",
    "\n",
    "class PredNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(PredNet, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_actor = config[\"n_actor\"]\n",
    "\n",
    "        pred = []\n",
    "        for i in range(config[\"num_mods\"]):\n",
    "            pred.append(\n",
    "                nn.Sequential(\n",
    "                    LinearRes(n_actor, n_actor, norm=norm, ng=ng),\n",
    "                    nn.Linear(n_actor, 2 * config[\"num_preds\"]),\n",
    "                )\n",
    "            )\n",
    "        self.pred = nn.ModuleList(pred)\n",
    "\n",
    "        self.att_dest = AttDest(n_actor)\n",
    "        self.cls = nn.Sequential(\n",
    "            LinearRes(n_actor, n_actor, norm=norm, ng=ng), nn.Linear(n_actor, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor]) -> Dict[str, List[Tensor]]:\n",
    "        preds = []\n",
    "        for i in range(len(self.pred)):\n",
    "            preds.append(self.pred[i](actors))\n",
    "        reg = torch.cat([x.unsqueeze(1) for x in preds], 1)\n",
    "        reg = reg.view(reg.size(0), reg.size(1), -1, 2)\n",
    "\n",
    "        n_c = self.config['dim_feats'][self.config['type_feats']][1]\n",
    "        for i in range(len(actor_idcs)):\n",
    "            idcs = actor_idcs[i]\n",
    "            ctrs = actor_ctrs[i].view(-1, 1, 1, n_c)\n",
    "            reg[idcs] = reg[idcs] + ctrs[:,:,:,:2]\n",
    "\n",
    "        dest_ctrs = reg[:, :, -1].detach()\n",
    "        feats = self.att_dest(actors, torch.cat(actor_ctrs, 0), dest_ctrs)\n",
    "        cls = self.cls(feats).view(-1, self.config[\"num_mods\"])\n",
    "\n",
    "        cls, sort_idcs = cls.sort(1, descending=True)\n",
    "        row_idcs = torch.arange(len(sort_idcs)).long().to(sort_idcs.device)\n",
    "        row_idcs = row_idcs.view(-1, 1).repeat(1, sort_idcs.size(1)).view(-1)\n",
    "        sort_idcs = sort_idcs.view(-1)\n",
    "        reg = reg[row_idcs, sort_idcs].view(cls.size(0), cls.size(1), -1, 2)\n",
    "\n",
    "        out = dict()\n",
    "        out[\"cls\"], out[\"reg\"] = [], []\n",
    "        for i in range(len(actor_idcs)):\n",
    "            idcs = actor_idcs[i]\n",
    "            out[\"cls\"].append(cls[idcs])\n",
    "            out[\"reg\"].append(reg[idcs])\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttDest(nn.Module):\n",
    "    def __init__(self, n_agt: int):\n",
    "        super(AttDest, self).__init__()\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        self.dist = nn.Sequential(\n",
    "            nn.Linear(2, n_agt),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_agt, n_agt, norm=norm, ng=ng),\n",
    "        )\n",
    "\n",
    "        self.agt = Linear(2 * n_agt, n_agt, norm=norm, ng=ng)\n",
    "\n",
    "    def forward(self, agts: Tensor, agt_ctrs: Tensor, dest_ctrs: Tensor) -> Tensor:\n",
    "        n_agt = agts.size(1)\n",
    "        num_mods = dest_ctrs.size(1)\n",
    "\n",
    "        dist = (agt_ctrs[:,:2].unsqueeze(1) - dest_ctrs).view(-1, 2)\n",
    "        dist = self.dist(dist)\n",
    "        agts = agts.unsqueeze(1).repeat(1, num_mods, 1).view(-1, n_agt)\n",
    "\n",
    "        agts = torch.cat((dist, agts), 1)\n",
    "        agts = self.agt(agts)\n",
    "        return agts\n",
    "\n",
    "\n",
    "class GreatNet(nn.Module):\n",
    "    def __init__(self,config) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.actor_net = ActorNet(config)\n",
    "        self.map_net = MapNet(config)\n",
    "\n",
    "        self.a2m = A2M(config)\n",
    "        self.m2m = M2M(config)\n",
    "        self.m2a = M2A(config)\n",
    "        self.a2a = A2A(config)\n",
    "        \n",
    "        self.pred_net = PredNet(config)\n",
    "    \n",
    "    def forward(self, data: Dict) -> Tensor:\n",
    "\n",
    "        actors, actor_idcs = actor_gather(data[\"feats\"])\n",
    "        actor_ctrs = [torch.stack(i,0) for i in data[\"ctrs\"]]\n",
    "\n",
    "        actors = gpu(actors)\n",
    "        actor_idcs = gpu(actor_idcs)\n",
    "        actor_ctrs = gpu(actor_ctrs)\n",
    "\n",
    "        actors = self.actor_net(actors)\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        graph = to_long(data['graph'])\n",
    "        graph = graph_gather(graph)\n",
    "\n",
    "        graph = gpu(graph)\n",
    "\n",
    "        nodes, node_idcs, node_ctrs = self.map_net(graph)\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "        \n",
    "        nodes = self.a2m(nodes, graph, actors, actor_idcs, actor_ctrs)\n",
    "        nodes = self.m2m(nodes, graph)\n",
    "        actors = self.m2a(actors, actor_idcs, actor_ctrs, nodes, node_idcs, node_ctrs)\n",
    "        actors = self.a2a(actors, actor_idcs, actor_ctrs)\n",
    "        \n",
    "        out = self.pred_net(actors, actor_idcs, actor_ctrs)\n",
    "        rot, orig = gpu(data[\"rot\"]), gpu(data[\"orig\"])\n",
    "\n",
    "        # to_global\n",
    "        for i in range(len(out[\"reg\"])):\n",
    "            out[\"reg\"][i] = torch.matmul(out[\"reg\"][i], rot[i]) + orig[i][:2].view(1, 1, 1, -1)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config['n_actornet'] = 128\n",
    "config['num_epochs'] = 150\n",
    "config['lr'] = 1e-3\n",
    "config[\"num_scales\"] = 6\n",
    "config[\"n_map\"] = 128\n",
    "config[\"n_actor\"] = 128\n",
    "config[\"actor2map_dist\"] = 7.0\n",
    "config[\"map2actor_dist\"] = 6.0\n",
    "config[\"actor2actor_dist\"] = 100.0\n",
    "config[\"num_mods\"] = 6\n",
    "config[\"pred_size\"] = 80\n",
    "config[\"pred_step\"] = 1\n",
    "config[\"num_preds\"] = config[\"pred_size\"] // config[\"pred_step\"]\n",
    "config[\"cls_th\"] = 2.0 #5.0\n",
    "config[\"cls_ignore\"] = 0.2\n",
    "config[\"mgn\"] = 0.2\n",
    "config[\"cls_coef\"] = 1.0\n",
    "config[\"reg_coef\"] = 1.0\n",
    "config[\"metrics_preds\"] = [30,50,80]\n",
    "config[\"dim_feats\"] = {'xyvp':[6,2], 'xyz':[4,3], 'xy':[3,2], 'xyp':[4,2]}\n",
    "config['type_feats'] = 'xyvp'\n",
    "config['f'] = '5f'\n",
    "config['train_split'] = '/home/avt/prediction/Waymo/data_processed/' + config['type_feats'] + '/train_' + config['f'] \n",
    "config['val_split'] = '/home/avt/prediction/Waymo/data_processed/' + config['type_feats'] + '/val_' + config['f']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajs = qq['trajs_xyz']\n",
    "# mask = qq['valid_masks']\n",
    "# velocity = qq['velocity_xy_heading']\n",
    "# orig = qq['orig']\n",
    "# theta = qq['theta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traj = trajs[6]\n",
    "# traj = to_local(traj,orig,theta)\n",
    "# traj = traj[mask[6]][:11]\n",
    "\n",
    "# vel = qq['feats'][6][:,2:4]\n",
    "\n",
    "# plt.plot(traj.T[0],traj.T[1],color = 'blue',linewidth = 1)\n",
    "# for i,t in enumerate(traj):\n",
    "#     plt.plot([t[0],t[0] + 0.1 * vel[i][0]],[t[1],t[1] + 0.1 * vel[i][1]],linewidth = 0.5)\n",
    "# plt.gca().set_aspect('equal')\n",
    "# plt.savefig('/home/avt/Desktop/plot.png', dpi=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traj = trajs[6]\n",
    "# vel = velocity[6]\n",
    "# traj = traj[mask[6]]\n",
    "# vel = vel[mask[6]]\n",
    "# plt.plot(traj.T[0],traj.T[1],color = 'blue',linewidth = 1)\n",
    "\n",
    "# for i,t in enumerate(traj):\n",
    "#     plt.plot([t[0],t[0] + 0.1 * vel[i][0]],[t[1],t[1] + 0.1 * vel[i][1]],linewidth = 0.5)\n",
    "\n",
    "\n",
    "# plt.gca().set_aspect('equal')\n",
    "# plt.xlim(2500,2700)\n",
    "# plt.ylim(400,600)\n",
    "# plt.savefig('/home/avt/Desktop/plot.png', dpi=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class W_Dataset(Dataset):\n",
    "    def __init__(self,path) -> None:\n",
    "\n",
    "        self.path = path\n",
    "        self.files = os.listdir(path)\n",
    "    \n",
    "    def __getitem__(self, index) -> dict:\n",
    "\n",
    "        data_path = os.path.join(self.path,self.files[index])\n",
    "        data = torch.load(data_path)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dataset_train = W_Dataset(config['train_split'])\n",
    "train_loader = DataLoader(dataset_train, \n",
    "                        batch_size = batch_size ,\n",
    "                        collate_fn = collate_fn, \n",
    "                        shuffle = True, \n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "        if i > 0:\n",
    "            break\n",
    "        zz = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_215758/2358674062.py:123: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.bn1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_215758/2358674062.py:124: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.bn2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_215758/2358674062.py:135: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  nn.GroupNorm(gcd(ng, n_out), n_out))\n",
      "/tmp/ipykernel_215758/2358674062.py:95: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_215758/2358674062.py:21: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_215758/2358674062.py:325: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
      "/tmp/ipykernel_215758/2358674062.py:414: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm = nn.GroupNorm(gcd(ng, n_agt), n_agt)\n",
      "/tmp/ipykernel_215758/2358674062.py:537: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
      "/tmp/ipykernel_215758/2358674062.py:48: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_215758/2358674062.py:49: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n"
     ]
    }
   ],
   "source": [
    "net = GreatNet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreatNet(\n",
       "  (actor_net): ActorNet(\n",
       "    (groups): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Res1d(\n",
       "          (conv1): Conv1d(6, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (bn1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (bn2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv1d(6, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Res1d(\n",
       "          (conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (bn1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (bn2): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Res1d(\n",
       "          (conv1): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "          (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (bn1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (bn2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv1d(32, 64, kernel_size=(1,), stride=(2,), bias=False)\n",
       "            (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Res1d(\n",
       "          (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (bn1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (bn2): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Res1d(\n",
       "          (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "          (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (bn1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (bn2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
       "            (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Res1d(\n",
       "          (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (bn1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (bn2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lateral): ModuleList(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(32, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv1d(\n",
       "        (conv): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv1d(\n",
       "        (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (outlayer): Res1d(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (bn2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (map_net): MapNet(\n",
       "    (input): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (seg): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(\n",
       "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fuse): ModuleDict(\n",
       "      (ctr): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (norm): ModuleList(\n",
       "        (0-3): 4 x GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (ctr2): ModuleList(\n",
       "        (0-3): 4 x Linear(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (left): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (right): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre0): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc0): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre1): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc1): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre2): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc2): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre3): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc3): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre4): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc4): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre5): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc5): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (a2m): A2M(\n",
       "    (meta): Linear(\n",
       "      (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (att): ModuleList(\n",
       "      (0-1): 2 x Att(\n",
       "        (dist): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(\n",
       "            (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (query): Linear(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (ctx): Sequential(\n",
       "          (0): Linear(\n",
       "            (linear): Linear(in_features=384, out_features=128, bias=False)\n",
       "            (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Linear(in_features=128, out_features=128, bias=False)\n",
       "        )\n",
       "        (agt): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (linear): Linear(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (m2m): M2M(\n",
       "    (fuse): ModuleDict(\n",
       "      (ctr): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (norm): ModuleList(\n",
       "        (0-3): 4 x GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (ctr2): ModuleList(\n",
       "        (0-3): 4 x Linear(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (left): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (right): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre0): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc0): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre1): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc1): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre2): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc2): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre3): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc3): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre4): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc4): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (pre5): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (suc5): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (m2a): M2A(\n",
       "    (att): ModuleList(\n",
       "      (0-1): 2 x Att(\n",
       "        (dist): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(\n",
       "            (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (query): Linear(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (ctx): Sequential(\n",
       "          (0): Linear(\n",
       "            (linear): Linear(in_features=384, out_features=128, bias=False)\n",
       "            (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Linear(in_features=128, out_features=128, bias=False)\n",
       "        )\n",
       "        (agt): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (linear): Linear(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (a2a): A2A(\n",
       "    (att): ModuleList(\n",
       "      (0-1): 2 x Att(\n",
       "        (dist): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(\n",
       "            (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (query): Linear(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (ctx): Sequential(\n",
       "          (0): Linear(\n",
       "            (linear): Linear(in_features=384, out_features=128, bias=False)\n",
       "            (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Linear(in_features=128, out_features=128, bias=False)\n",
       "        )\n",
       "        (agt): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (linear): Linear(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pred_net): PredNet(\n",
       "    (pred): ModuleList(\n",
       "      (0-5): 6 x Sequential(\n",
       "        (0): LinearRes(\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (norm1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (norm2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1): Linear(in_features=128, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (att_dest): AttDest(\n",
       "      (dist): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(\n",
       "          (linear): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (agt): Linear(\n",
       "        (linear): Linear(in_features=256, out_features=128, bias=False)\n",
       "        (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (cls): Sequential(\n",
       "      (0): LinearRes(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (norm1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (norm2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 80, 2]) torch.Size([5, 80, 2]) torch.Size([5, 80])\n"
     ]
    }
   ],
   "source": [
    "reg = out['reg']\n",
    "indx = zz['target_indx_e']\n",
    "gt_preds, has_preds = gather(zz['gt_preds']), gather(zz['has_preds'])\n",
    "r,g,h=[],[],[]\n",
    "    \n",
    "for i in range(len(indx)):\n",
    "    mask = torch.tensor(indx[i])\n",
    "    r.append(reg[i][mask])\n",
    "    g.append(gt_preds[i][mask])\n",
    "    h.append(has_preds[i][mask])\n",
    "\n",
    "print(r[0].shape,g[0].shape,h[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(p_reg,data):\n",
    "\n",
    "    reg = p_reg\n",
    "    indx = data['target_indx_e']\n",
    "    gt_preds, has_preds = gather(data['gt_preds']), gather(data['has_preds'])\n",
    "\n",
    "    \n",
    "    \n",
    "    return r,g,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg, gt_preds, has_preds = get_target(out['reg'],zz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([5, 6, 80, 2]),\n",
       " torch.Size([5, 6, 80, 2]),\n",
       " torch.Size([1, 6, 80, 2]),\n",
       " torch.Size([2, 6, 80, 2])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r.shape for r in reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ -1569.0692, -12179.6074],\n",
       "         [ -1569.0514, -12179.8047],\n",
       "         [ -1569.0366, -12179.9824],\n",
       "         [ -1569.0236, -12180.1689],\n",
       "         [ -1569.0073, -12180.3906],\n",
       "         [ -1569.0002, -12180.6133],\n",
       "         [ -1569.0046, -12180.8623],\n",
       "         [ -1569.0017, -12181.0957],\n",
       "         [ -1569.0111, -12181.3740],\n",
       "         [ -1569.0140, -12181.5879],\n",
       "         [ -1569.0319, -12181.8252],\n",
       "         [ -1569.0536, -12182.1016],\n",
       "         [ -1569.0876, -12182.3936],\n",
       "         [ -1569.1304, -12182.6699],\n",
       "         [ -1569.1930, -12182.9648],\n",
       "         [ -1569.2637, -12183.2715],\n",
       "         [ -1569.3406, -12183.5781],\n",
       "         [ -1569.4341, -12183.9004],\n",
       "         [ -1569.5405, -12184.2129],\n",
       "         [ -1569.6730, -12184.5430],\n",
       "         [ -1569.8253, -12184.9053],\n",
       "         [ -1569.9901, -12185.2529],\n",
       "         [ -1570.1796, -12185.6211],\n",
       "         [ -1570.4113, -12186.0146],\n",
       "         [ -1570.6354, -12186.3750],\n",
       "         [ -1570.8859, -12186.7129],\n",
       "         [ -1571.1417, -12187.0410],\n",
       "         [ -1571.4305, -12187.3926],\n",
       "         [ -1571.7429, -12187.7432],\n",
       "         [ -1572.0840, -12188.0771],\n",
       "         [ -1572.4650, -12188.4346],\n",
       "         [ -1572.8542, -12188.7471],\n",
       "         [ -1573.2463, -12189.0586],\n",
       "         [ -1573.6770, -12189.3555],\n",
       "         [ -1574.1239, -12189.6299],\n",
       "         [ -1574.5757, -12189.8848],\n",
       "         [ -1575.0219, -12190.1055],\n",
       "         [ -1575.5200, -12190.3193],\n",
       "         [ -1576.0022, -12190.5049],\n",
       "         [ -1576.4578, -12190.6553],\n",
       "         [ -1576.9702, -12190.8164],\n",
       "         [ -1577.4591, -12190.9453],\n",
       "         [ -1578.0105, -12191.0752],\n",
       "         [ -1578.5784, -12191.1934],\n",
       "         [ -1579.1343, -12191.2852],\n",
       "         [ -1579.7208, -12191.3857],\n",
       "         [ -1580.3496, -12191.4863],\n",
       "         [ -1580.9774, -12191.5723],\n",
       "         [ -1581.6210, -12191.6582],\n",
       "         [ -1582.2960, -12191.7393],\n",
       "         [ -1582.9396, -12191.8115],\n",
       "         [ -1583.6445, -12191.8906],\n",
       "         [ -1584.3445, -12191.9648],\n",
       "         [ -1585.0083, -12192.0488],\n",
       "         [ -1585.6791, -12192.1221],\n",
       "         [ -1586.4368, -12192.1807],\n",
       "         [ -1587.1318, -12192.2559],\n",
       "         [ -1587.8680, -12192.3340],\n",
       "         [ -1588.5808, -12192.4023],\n",
       "         [ -1589.2965, -12192.4590],\n",
       "         [ -1589.9987, -12192.5244],\n",
       "         [ -1590.7109, -12192.5977],\n",
       "         [ -1591.4705, -12192.6650],\n",
       "         [ -1592.1823, -12192.7354],\n",
       "         [ -1592.8883, -12192.8145],\n",
       "         [ -1593.6300, -12192.8818],\n",
       "         [ -1594.3787, -12192.9541],\n",
       "         [ -1595.1205, -12193.0264],\n",
       "         [ -1595.8647, -12193.0947],\n",
       "         [ -1596.6031, -12193.1660],\n",
       "         [ -1597.3121, -12193.2266],\n",
       "         [ -1598.0463, -12193.3105],\n",
       "         [ -1598.7424, -12193.3828],\n",
       "         [ -1599.4470, -12193.4629],\n",
       "         [ -1600.2034, -12193.5371],\n",
       "         [ -1600.9235, -12193.6035],\n",
       "         [ -1601.6593, -12193.6650],\n",
       "         [ -1602.3893, -12193.7246],\n",
       "         [ -1603.1337, -12193.7871],\n",
       "         [ -1603.8835, -12193.8467]], dtype=torch.float64),\n",
       " tensor([[ -1555.5961, -12204.4492],\n",
       "         [ -1555.5961, -12204.4492],\n",
       "         [ -1555.5961, -12204.4492],\n",
       "         [ -1555.5961, -12204.4492],\n",
       "         [ -1555.5961, -12204.4492],\n",
       "         [ -1555.5961, -12204.4492],\n",
       "         [ -1555.5961, -12204.4492],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [ -1558.0963, -12205.7314],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [ -1573.2578, -12211.1104],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [ -1563.2472, -12207.4824],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [ -1565.9915, -12208.4756],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [ -1554.0671, -12218.7969],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [ -1568.5630, -12209.4092],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [ -1575.6171, -12211.9453],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [ -1588.8672, -12216.6191],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1545.0048, -12196.0586],\n",
       "         [ -1544.8521, -12196.5889],\n",
       "         [ -1544.6779, -12197.1309],\n",
       "         [ -1544.5145, -12197.6553],\n",
       "         [ -1544.3470, -12198.1729],\n",
       "         [ -1544.1823, -12198.6895],\n",
       "         [ -1544.0304, -12199.1846],\n",
       "         [ -1543.8584, -12199.7148],\n",
       "         [ -1543.7111, -12200.2080],\n",
       "         [ -1543.5339, -12200.7383],\n",
       "         [ -1543.3571, -12201.2344],\n",
       "         [ -1543.1832, -12201.7080],\n",
       "         [ -1543.0094, -12202.1846],\n",
       "         [ -1542.8444, -12202.6650],\n",
       "         [ -1542.7372, -12203.0498],\n",
       "         [ -1542.5605, -12203.5723],\n",
       "         [ -1542.3839, -12204.0635],\n",
       "         [ -1542.1940, -12204.6914],\n",
       "         [ -1541.9757, -12205.1104],\n",
       "         [ -1541.7615, -12205.6631],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [ -1584.5745, -12230.5264],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [ -1552.6874, -12203.8857],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209],\n",
       "         [ -1586.1045, -12216.4209]], dtype=torch.float64),\n",
       " tensor([[ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [ -1583.1919, -12215.5127],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1556.7133, -12220.1621],\n",
       "         [ -1556.7133, -12220.1621],\n",
       "         [ -1556.7133, -12220.1621],\n",
       "         [ -1556.7133, -12220.1621],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1572.0398, -12225.5059],\n",
       "         [ -1572.0398, -12225.5059],\n",
       "         [ -1572.0398, -12225.5059],\n",
       "         [ -1572.0398, -12225.5059],\n",
       "         [ -1572.0398, -12225.5059],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1566.5178, -12245.1299],\n",
       "         [ -1566.5178, -12245.1299],\n",
       "         [ -1566.5178, -12245.1299],\n",
       "         [ -1566.5178, -12245.1299],\n",
       "         [ -1566.5178, -12245.1299],\n",
       "         [ -1566.5178, -12245.1299],\n",
       "         [ -1566.5178, -12245.1299],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1630.9462, -12211.3994],\n",
       "         [ -1630.9448, -12211.3701],\n",
       "         [ -1630.9424, -12211.3213],\n",
       "         [ -1630.9375, -12211.2598],\n",
       "         [ -1630.9290, -12211.2012],\n",
       "         [ -1630.9142, -12211.1211],\n",
       "         [ -1630.9128, -12211.0439],\n",
       "         [ -1630.8979, -12210.9570],\n",
       "         [ -1630.8892, -12210.8496],\n",
       "         [ -1630.8743, -12210.7500],\n",
       "         [ -1630.8679, -12210.6562],\n",
       "         [ -1630.8597, -12210.5547],\n",
       "         [ -1630.8524, -12210.4658],\n",
       "         [ -1630.8438, -12210.3672],\n",
       "         [ -1630.8342, -12210.2939],\n",
       "         [ -1630.8273, -12210.2041],\n",
       "         [ -1630.8182, -12210.1309],\n",
       "         [ -1630.8140, -12210.0498],\n",
       "         [ -1630.8048, -12209.9756],\n",
       "         [ -1630.8032, -12209.9248],\n",
       "         [ -1630.7975, -12209.8613],\n",
       "         [ -1630.7949, -12209.7949],\n",
       "         [ -1630.7941, -12209.7256],\n",
       "         [ -1630.7852, -12209.6338],\n",
       "         [ -1630.7737, -12209.5664],\n",
       "         [ -1630.7659, -12209.4639],\n",
       "         [ -1630.7563, -12209.3564],\n",
       "         [ -1630.7429, -12209.2549],\n",
       "         [ -1630.7291, -12209.1416],\n",
       "         [ -1630.7205, -12209.0166],\n",
       "         [ -1630.7063, -12208.8721],\n",
       "         [ -1630.6945, -12208.7217],\n",
       "         [ -1630.6831, -12208.5801],\n",
       "         [ -1630.6678, -12208.4141],\n",
       "         [ -1630.6503, -12208.2627],\n",
       "         [ -1630.6333, -12208.0859],\n",
       "         [ -1630.6230, -12207.9111],\n",
       "         [ -1630.6151, -12207.7334],\n",
       "         [ -1630.6077, -12207.5654],\n",
       "         [ -1630.5974, -12207.3672],\n",
       "         [ -1630.5913, -12207.1221],\n",
       "         [ -1630.5914, -12206.8477],\n",
       "         [ -1630.5967, -12206.5645],\n",
       "         [ -1630.6144, -12206.2100],\n",
       "         [ -1630.6361, -12205.8848],\n",
       "         [ -1630.6742, -12205.5410],\n",
       "         [ -1630.7159, -12205.1582],\n",
       "         [ -1630.7762, -12204.7920],\n",
       "         [ -1630.8445, -12204.4033],\n",
       "         [ -1630.9349, -12203.9951],\n",
       "         [ -1631.0398, -12203.5879],\n",
       "         [ -1631.1644, -12203.1758],\n",
       "         [ -1631.2996, -12202.7480],\n",
       "         [ -1631.4418, -12202.3369],\n",
       "         [ -1631.6080, -12201.9248],\n",
       "         [ -1631.7976, -12201.5049],\n",
       "         [ -1632.0110, -12201.0742],\n",
       "         [ -1632.2378, -12200.6426],\n",
       "         [ -1632.4977, -12200.2188],\n",
       "         [ -1632.7795, -12199.7910],\n",
       "         [ -1633.0928, -12199.3750],\n",
       "         [ -1633.4299, -12198.9805],\n",
       "         [ -1633.7860, -12198.6230],\n",
       "         [ -1634.1493, -12198.2783],\n",
       "         [ -1634.5398, -12197.9697],\n",
       "         [ -1634.9403, -12197.6875],\n",
       "         [ -1635.3660, -12197.4199],\n",
       "         [ -1635.7847, -12197.2070],\n",
       "         [ -1636.2244, -12197.0166],\n",
       "         [ -1636.6898, -12196.8320],\n",
       "         [ -1637.1653, -12196.6875],\n",
       "         [ -1637.6702, -12196.5566],\n",
       "         [ -1638.1782, -12196.4531],\n",
       "         [ -1638.7334, -12196.3516],\n",
       "         [ -1639.3234, -12196.2705],\n",
       "         [ -1639.9194, -12196.2031],\n",
       "         [ -1640.5083, -12196.1553],\n",
       "         [ -1641.1321, -12196.1152],\n",
       "         [ -1641.7810, -12196.0928],\n",
       "         [ -1642.4152, -12196.0820]], dtype=torch.float64),\n",
       " tensor([[ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [ -1566.5780, -12223.9355],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1564.9425, -12229.2881],\n",
       "         [ -1564.9425, -12229.2881],\n",
       "         [ -1564.9425, -12229.2881],\n",
       "         [ -1564.9425, -12229.2881],\n",
       "         [ -1564.9425, -12229.2881],\n",
       "         [ -1564.9425, -12229.2881],\n",
       "         [ -1564.9425, -12229.2881],\n",
       "         [ -1564.9425, -12229.2881],\n",
       "         [ -1564.9425, -12229.2881],\n",
       "         [ -1564.9425, -12229.2881],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1573.8468, -12248.5889],\n",
       "         [ -1573.8468, -12248.5889],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428],\n",
       "         [ -1612.6102, -12220.3428]], dtype=torch.float64),\n",
       " tensor([[ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [ -1559.6460, -12227.1055],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1551.7042, -12246.3799],\n",
       "         [ -1551.7042, -12246.3799],\n",
       "         [ -1551.7042, -12246.3799],\n",
       "         [ -1551.7042, -12246.3799],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1551.7042, -12246.3799],\n",
       "         [ -1551.7042, -12246.3799],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1598.2308, -12234.3516],\n",
       "         [ -1598.2166, -12234.2842],\n",
       "         [ -1598.2073, -12234.2422],\n",
       "         [ -1598.2184, -12234.1709],\n",
       "         [ -1598.2324, -12234.1162],\n",
       "         [ -1598.2305, -12234.0791],\n",
       "         [ -1598.2393, -12234.0576],\n",
       "         [ -1598.2491, -12234.0234],\n",
       "         [ -1598.2545, -12233.9795],\n",
       "         [ -1598.2693, -12233.9033],\n",
       "         [ -1598.2655, -12233.8887],\n",
       "         [ -1598.2639, -12233.8369],\n",
       "         [ -1598.2770, -12233.7900],\n",
       "         [ -1598.2872, -12233.6963],\n",
       "         [ -1598.2950, -12233.6279],\n",
       "         [ -1598.3102, -12233.5410],\n",
       "         [ -1598.3206, -12233.4463],\n",
       "         [ -1598.3231, -12233.3662],\n",
       "         [ -1598.3346, -12233.2969],\n",
       "         [ -1598.3440, -12233.1797],\n",
       "         [ -1598.3489, -12233.0938],\n",
       "         [ -1598.3420, -12232.9990],\n",
       "         [ -1598.3348, -12232.9414],\n",
       "         [ -1598.3401, -12232.8564],\n",
       "         [ -1598.3528, -12232.7373],\n",
       "         [ -1598.3501, -12232.6787],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1598.3488, -12232.3789],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1598.3528, -12232.3525],\n",
       "         [ -1598.2986, -12232.3340],\n",
       "         [ -1598.3430, -12232.3018],\n",
       "         [ -1598.3438, -12232.2539],\n",
       "         [ -1598.3458, -12232.2188],\n",
       "         [ -1598.3425, -12232.1582],\n",
       "         [ -1598.3345, -12232.1416],\n",
       "         [ -1598.3341, -12232.1318],\n",
       "         [ -1598.3324, -12232.1250],\n",
       "         [ -1598.3322, -12232.1074],\n",
       "         [ -1598.3357, -12232.1025],\n",
       "         [ -1598.3326, -12232.0859],\n",
       "         [ -1598.3405, -12232.0742],\n",
       "         [ -1598.3378, -12232.0654],\n",
       "         [ -1598.3392, -12232.0205],\n",
       "         [ -1598.3320, -12232.0000],\n",
       "         [ -1598.3181, -12231.9883],\n",
       "         [ -1598.3118, -12231.9658],\n",
       "         [ -1598.3091, -12231.9268],\n",
       "         [ -1598.3027, -12231.8750],\n",
       "         [ -1598.3005, -12231.8418],\n",
       "         [ -1598.2953, -12231.7969],\n",
       "         [ -1598.2867, -12231.7295],\n",
       "         [ -1598.2739, -12231.6943],\n",
       "         [ -1598.2656, -12231.6240],\n",
       "         [ -1598.2524, -12231.5400],\n",
       "         [ -1598.2360, -12231.4443],\n",
       "         [ -1598.2200, -12231.4297],\n",
       "         [ -1598.1915, -12231.4375],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [ -1554.3584, -12226.2969],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1575.0757, -12141.2256],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1574.6510, -12144.1553],\n",
       "         [ -1574.6007, -12144.7402],\n",
       "         [ -1574.4739, -12145.4150],\n",
       "         [ -1574.3796, -12146.1328],\n",
       "         [ -1574.2723, -12146.8525],\n",
       "         [ -1574.1798, -12147.5127],\n",
       "         [ -1574.0750, -12148.1943],\n",
       "         [ -1573.9851, -12148.9053],\n",
       "         [ -1573.8860, -12149.5869],\n",
       "         [ -1573.7792, -12150.2656],\n",
       "         [ -1573.6796, -12150.9404],\n",
       "         [ -1573.5720, -12151.6494],\n",
       "         [ -1573.4598, -12152.3369],\n",
       "         [ -1573.3574, -12153.0049],\n",
       "         [ -1573.2574, -12153.6514],\n",
       "         [ -1573.1554, -12154.3369],\n",
       "         [ -1573.0527, -12155.0000],\n",
       "         [ -1572.9603, -12155.6719],\n",
       "         [ -1572.8623, -12156.3447],\n",
       "         [ -1572.7605, -12157.0244],\n",
       "         [ -1572.6621, -12157.6729],\n",
       "         [ -1572.5638, -12158.3389],\n",
       "         [ -1572.4670, -12159.0098],\n",
       "         [ -1572.3806, -12159.6709],\n",
       "         [ -1572.2983, -12160.2021],\n",
       "         [ -1572.1862, -12160.9121],\n",
       "         [ -1572.1074, -12161.5938],\n",
       "         [ -1572.0128, -12162.2070],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1571.8032, -12163.4326],\n",
       "         [ -1571.7153, -12164.0039],\n",
       "         [ -1571.6171, -12164.6104],\n",
       "         [ -1571.5103, -12165.2832],\n",
       "         [ -1571.4249, -12165.8721],\n",
       "         [ -1571.3389, -12166.4102],\n",
       "         [ -1571.2556, -12167.0430],\n",
       "         [ -1571.1648, -12167.6865],\n",
       "         [ -1571.0715, -12168.3330],\n",
       "         [ -1570.9897, -12168.9463],\n",
       "         [ -1570.9136, -12169.5205],\n",
       "         [ -1570.8374, -12170.1299],\n",
       "         [ -1570.7578, -12170.5918],\n",
       "         [ -1570.6895, -12171.1553],\n",
       "         [ -1570.6024, -12171.6016],\n",
       "         [ -1570.5433, -12172.0498],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1570.4042, -12173.0771],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1570.1123, -12175.4102],\n",
       "         [ -1570.0537, -12175.7764],\n",
       "         [ -1569.9912, -12176.1680],\n",
       "         [ -1569.9536, -12176.6729],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787],\n",
       "         [ -1618.0591, -12234.6787]], dtype=torch.float64),\n",
       " tensor([[     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1553.4153, -12240.4717],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1649.2349, -12203.0801],\n",
       "         [ -1649.1129, -12203.0645],\n",
       "         [ -1648.9832, -12203.0537],\n",
       "         [ -1648.8826, -12203.0400],\n",
       "         [ -1648.7161, -12203.0273],\n",
       "         [ -1648.6490, -12203.0205],\n",
       "         [ -1648.5090, -12202.9951],\n",
       "         [ -1648.4152, -12202.9893],\n",
       "         [ -1648.3389, -12202.9824],\n",
       "         [ -1648.2620, -12202.9736],\n",
       "         [ -1648.1635, -12202.9609],\n",
       "         [ -1648.1069, -12202.9541],\n",
       "         [ -1648.0206, -12202.9434],\n",
       "         [ -1647.9805, -12202.9385],\n",
       "         [ -1647.8695, -12202.9268],\n",
       "         [ -1647.8260, -12202.9199],\n",
       "         [ -1647.7410, -12202.9082],\n",
       "         [ -1647.6514, -12202.9004],\n",
       "         [ -1647.5619, -12202.8838],\n",
       "         [ -1647.4913, -12202.8721],\n",
       "         [ -1647.3826, -12202.8584],\n",
       "         [ -1647.2937, -12202.8506],\n",
       "         [ -1647.1769, -12202.8350],\n",
       "         [ -1647.0776, -12202.8232],\n",
       "         [ -1646.9905, -12202.8105],\n",
       "         [ -1646.8944, -12202.7969],\n",
       "         [ -1646.7950, -12202.7881],\n",
       "         [ -1646.7046, -12202.7715],\n",
       "         [ -1646.5918, -12202.7568],\n",
       "         [ -1646.4866, -12202.7432],\n",
       "         [ -1646.3987, -12202.7354],\n",
       "         [ -1646.2788, -12202.7168],\n",
       "         [ -1646.1688, -12202.7002],\n",
       "         [ -1646.0601, -12202.6865],\n",
       "         [ -1645.9310, -12202.6641],\n",
       "         [ -1645.8093, -12202.6484],\n",
       "         [ -1645.6814, -12202.6299],\n",
       "         [ -1645.5386, -12202.6064],\n",
       "         [ -1645.4037, -12202.5908],\n",
       "         [ -1645.2620, -12202.5674],\n",
       "         [ -1645.1110, -12202.5439],\n",
       "         [ -1644.9480, -12202.5156],\n",
       "         [ -1644.7947, -12202.4922],\n",
       "         [ -1644.6349, -12202.4658],\n",
       "         [ -1644.4600, -12202.4355],\n",
       "         [ -1644.2871, -12202.4043],\n",
       "         [ -1644.1052, -12202.3682],\n",
       "         [ -1643.9244, -12202.3301],\n",
       "         [ -1643.7435, -12202.2930],\n",
       "         [ -1643.5505, -12202.2490],\n",
       "         [ -1643.3663, -12202.2051],\n",
       "         [ -1643.1696, -12202.1553],\n",
       "         [ -1642.9821, -12202.0996],\n",
       "         [ -1642.8004, -12202.0508],\n",
       "         [ -1642.6357, -12202.0020],\n",
       "         [ -1642.4843, -12201.9590],\n",
       "         [ -1642.3524, -12201.9180],\n",
       "         [ -1642.2346, -12201.8789],\n",
       "         [ -1642.1400, -12201.8506],\n",
       "         [ -1642.0535, -12201.8252],\n",
       "         [ -1642.0012, -12201.8066],\n",
       "         [ -1641.9528, -12201.7852],\n",
       "         [ -1641.9091, -12201.7695],\n",
       "         [ -1641.8906, -12201.7715],\n",
       "         [ -1641.8632, -12201.7607],\n",
       "         [ -1641.8392, -12201.7412],\n",
       "         [ -1641.8191, -12201.7422],\n",
       "         [ -1641.8234, -12201.7471],\n",
       "         [ -1641.8209, -12201.7490],\n",
       "         [ -1641.8051, -12201.7451],\n",
       "         [ -1641.8114, -12201.7490],\n",
       "         [ -1641.8054, -12201.7422],\n",
       "         [ -1641.8005, -12201.7402],\n",
       "         [ -1641.8167, -12201.7441],\n",
       "         [ -1641.8182, -12201.7559],\n",
       "         [ -1641.8195, -12201.7490],\n",
       "         [ -1641.8173, -12201.7510],\n",
       "         [ -1641.8256, -12201.7500],\n",
       "         [ -1641.8157, -12201.7480],\n",
       "         [ -1641.8221, -12201.7539]], dtype=torch.float64),\n",
       " tensor([[ -1623.2317, -12253.7725],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551],\n",
       "         [ -1609.7332, -12233.9551]], dtype=torch.float64),\n",
       " tensor([[ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [ -1551.0879, -12239.4639],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783],\n",
       "         [ -1598.9630, -12220.2783]], dtype=torch.float64),\n",
       " tensor([[ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404],\n",
       "         [ -1669.7217, -12192.9404]], dtype=torch.float64),\n",
       " tensor([[ -1622.9824, -12260.1055],\n",
       "         [ -1622.9824, -12260.1055],\n",
       "         [ -1622.9824, -12260.1055],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463],\n",
       "         [ -1671.5916, -12190.9463]], dtype=torch.float64),\n",
       " tensor([[ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529],\n",
       "         [ -1673.2358, -12188.7529]], dtype=torch.float64),\n",
       " tensor([[ -1538.3239, -12215.3262],\n",
       "         [ -1538.1887, -12215.7041],\n",
       "         [ -1538.0742, -12216.0342],\n",
       "         [ -1537.9602, -12216.3623],\n",
       "         [ -1537.8276, -12216.7041],\n",
       "         [ -1537.7291, -12216.9668],\n",
       "         [ -1537.6028, -12217.2910],\n",
       "         [ -1537.4998, -12217.5967],\n",
       "         [ -1537.3934, -12217.8428],\n",
       "         [ -1537.2689, -12218.1270],\n",
       "         [ -1537.1484, -12218.4854],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016],\n",
       "         [ -1675.0571, -12186.6016]], dtype=torch.float64),\n",
       " tensor([[ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062],\n",
       "         [ -1666.3667, -12159.4062]], dtype=torch.float64),\n",
       " tensor([[ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420],\n",
       "         [ -1668.1740, -12162.0420]], dtype=torch.float64),\n",
       " tensor([[ -1671.6306, -12167.1543],\n",
       "         [ -1671.6306, -12167.1543],\n",
       "         [ -1671.6306, -12167.1543],\n",
       "         [ -1671.6306, -12167.1543],\n",
       "         [ -1671.6306, -12167.1543],\n",
       "         [ -1671.6306, -12167.1543],\n",
       "         [ -1671.6306, -12167.1543],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154],\n",
       "         [ -1654.7129, -12146.8154]], dtype=torch.float64),\n",
       " tensor([[ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195],\n",
       "         [ -1626.1533, -12241.0195]], dtype=torch.float64),\n",
       " tensor([[ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684],\n",
       "         [ -1620.9447, -12235.0684]], dtype=torch.float64),\n",
       " tensor([[ -1612.6724, -12240.6484],\n",
       "         [ -1612.6724, -12240.6484],\n",
       "         [ -1612.6724, -12240.6484],\n",
       "         [ -1612.6724, -12240.6484],\n",
       "         [ -1612.6724, -12240.6484],\n",
       "         [ -1612.6724, -12240.6484],\n",
       "         [ -1612.6724, -12240.6484],\n",
       "         [ -1612.6724, -12240.6484],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1612.6724, -12240.6484],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [ -1612.6724, -12240.6484],\n",
       "         [ -1612.6724, -12240.6484],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000]], dtype=torch.float64),\n",
       " tensor([[ -1603.0018, -12193.7090],\n",
       "         [ -1603.6686, -12193.7638],\n",
       "         [ -1604.3360, -12193.8194],\n",
       "         [ -1605.0039, -12193.8692],\n",
       "         [ -1605.6728, -12193.9192],\n",
       "         [ -1606.3422, -12193.9651],\n",
       "         [ -1607.0118, -12194.0087],\n",
       "         [ -1607.6827, -12194.0519],\n",
       "         [ -1608.3537, -12194.0915],\n",
       "         [ -1609.0246, -12194.1314],\n",
       "         [ -1609.6961, -12194.1689],\n",
       "         [ -1610.3663, -12194.2049],\n",
       "         [ -1611.0367, -12194.2404],\n",
       "         [ -1611.7061, -12194.2733],\n",
       "         [ -1612.3755, -12194.3059],\n",
       "         [ -1613.0441, -12194.3388],\n",
       "         [ -1613.7139, -12194.3685],\n",
       "         [ -1614.3865, -12194.3998],\n",
       "         [ -1615.0564, -12194.4308],\n",
       "         [ -1615.7256, -12194.4622],\n",
       "         [ -1616.3949, -12194.4933],\n",
       "         [ -1617.0640, -12194.5247],\n",
       "         [ -1617.7338, -12194.5567],\n",
       "         [ -1618.4044, -12194.5877],\n",
       "         [ -1619.0747, -12194.6214],\n",
       "         [ -1619.7441, -12194.6518],\n",
       "         [ -1620.4138, -12194.6842],\n",
       "         [ -1621.0833, -12194.7152],\n",
       "         [ -1621.7546, -12194.7476],\n",
       "         [ -1622.4289, -12194.7787],\n",
       "         [ -1623.1036, -12194.8090],\n",
       "         [ -1623.7784, -12194.8416],\n",
       "         [ -1624.4536, -12194.8733],\n",
       "         [ -1625.1316, -12194.9042],\n",
       "         [ -1625.8079, -12194.9412],\n",
       "         [ -1626.4823, -12194.9713],\n",
       "         [ -1627.1565, -12195.0075],\n",
       "         [ -1627.8293, -12195.0426],\n",
       "         [ -1628.5003, -12195.0779],\n",
       "         [ -1629.1716, -12195.1167],\n",
       "         [ -1629.8405, -12195.1522],\n",
       "         [ -1630.5078, -12195.1917],\n",
       "         [ -1631.1742, -12195.2284],\n",
       "         [ -1631.8403, -12195.2660],\n",
       "         [ -1632.5068, -12195.3022],\n",
       "         [ -1633.1758, -12195.3373],\n",
       "         [ -1633.8473, -12195.3714],\n",
       "         [ -1634.5202, -12195.4068],\n",
       "         [ -1635.1963, -12195.4410],\n",
       "         [ -1635.8754, -12195.4763],\n",
       "         [ -1636.5552, -12195.5111],\n",
       "         [ -1637.2356, -12195.5415],\n",
       "         [ -1637.9164, -12195.5749],\n",
       "         [ -1638.5972, -12195.6083],\n",
       "         [ -1639.2797, -12195.6427],\n",
       "         [ -1639.9632, -12195.6806],\n",
       "         [ -1640.6493, -12195.7179],\n",
       "         [ -1641.3363, -12195.7592],\n",
       "         [ -1642.0200, -12195.7997],\n",
       "         [ -1642.6998, -12195.8436],\n",
       "         [ -1643.3775, -12195.8906],\n",
       "         [ -1644.0481, -12195.9413],\n",
       "         [ -1644.7094, -12195.9930],\n",
       "         [ -1645.3622, -12196.0480],\n",
       "         [ -1646.0066, -12196.1048],\n",
       "         [ -1646.6433, -12196.1631],\n",
       "         [ -1647.2743, -12196.2244],\n",
       "         [ -1647.8986, -12196.2871],\n",
       "         [ -1648.5184, -12196.3528],\n",
       "         [ -1649.1337, -12196.4178],\n",
       "         [ -1649.7433, -12196.4858],\n",
       "         [ -1650.3487, -12196.5547],\n",
       "         [ -1650.9473, -12196.6247],\n",
       "         [ -1651.5352, -12196.6963],\n",
       "         [ -1652.1175, -12196.7675],\n",
       "         [ -1652.6915, -12196.8416],\n",
       "         [ -1653.2566, -12196.9147],\n",
       "         [ -1653.8138, -12196.9880],\n",
       "         [ -1654.3670, -12197.0649],\n",
       "         [ -1654.9129, -12197.1404]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz['gt_preds'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = torch.ones(5,5)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = torch.cumsum(dd,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5., 5.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = np.array([1,3])\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2., 2.],\n",
       "        [4., 4., 4., 4., 4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd[pp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
