{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to figure out M6 post and to_world.\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from fractions import gcd\n",
    "from numbers import Number\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from utils import collate_fn,gpu,to_long\n",
    "import logging\n",
    "from memory_profiler import profile\n",
    "import gc\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import copy\n",
    "import torch\n",
    "from utils import poly_gon_and_line,bboxes_overlapping,bboxes_of_poly, to_local\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "config = dict()\n",
    "config['n_actornet'] = 128\n",
    "config['num_epochs'] = 150\n",
    "config['lr'] = 1e-3\n",
    "config[\"num_scales\"] = 6\n",
    "config[\"n_map\"] = 128\n",
    "config[\"n_actor\"] = 128\n",
    "config[\"actor2map_dist\"] = 7.0\n",
    "config[\"map2actor_dist\"] = 6.0\n",
    "config[\"actor2actor_dist\"] = 100.0\n",
    "config[\"num_mods\"] = 6\n",
    "config[\"pred_size\"] = 80\n",
    "config[\"pred_step\"] = 1\n",
    "config[\"num_preds\"] = config[\"pred_size\"] // config[\"pred_step\"]\n",
    "config[\"cls_th\"] = 2.0 #5.0\n",
    "config[\"cls_ignore\"] = 0.2\n",
    "config[\"mgn\"] = 0.2\n",
    "config[\"cls_coef\"] = 1.0\n",
    "config[\"reg_coef\"] = 1.0\n",
    "config[\"metrics_preds\"] = [30,50,80]\n",
    "config[\"dim_feats\"] = {'xyvp':[6,2], 'xyz':[4,3], 'xy':[3,2], 'xyp':[4,2], 'vp':[4,2]}\n",
    "config['type_feats'] = 'vp'\n",
    "config['f'] = '1f'\n",
    "config['train_split'] = '/home/avt/prediction/Waymo/data_processed/' + config['type_feats'] + '/train_' + config['f'] \n",
    "config['val_split'] = '/home/avt/prediction/Waymo/data_processed/' + config['type_feats'] + '/val_' + config['f']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_VEHICLE',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_PEDESTRIAN',\n",
       " 'TYPE_VEHICLE']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/avt/prediction/Waymo/data_processed/xy/train_1f/0_3.pt'\n",
    "qq = torch.load(path)\n",
    "qq['object_types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/home/avt/prediction/Waymo/data_processed/xy/train_1f/0_3.pt'\n",
    "qq = torch.load(path)\n",
    "ctrs = qq['graph']['ctrs']\n",
    "\n",
    "for c in ctrs:\n",
    "    plt.scatter(ctrs.T[0] ,ctrs.T[1], c = 'black',s = 0.05)\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('x(m)')\n",
    "plt.ylabel('y(m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/home/avt/prediction/Waymo/data_processed/xy/train_1f/1_3.pt'\n",
    "qq = torch.load(path)\n",
    "ctrs = qq['graph']['ctrs']\n",
    "\n",
    "for c in ctrs:\n",
    "    plt.scatter(ctrs.T[0] ,ctrs.T[1], c = 'black',s = 0.05)\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('x(m)')\n",
    "plt.ylabel('y(m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/avt/prediction/Waymo/working/')\n",
    "\n",
    "from math import gcd\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from typing import Dict, List, Tuple, Union\n",
    "from utils import to_long, gpu\n",
    "\n",
    "# config[\"dim_feats\"] = {'xyvp':[6,2], 'xyz':[4,3], 'xy':[3,2],  'xyp':[4,2]}\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_in, n_out, norm='GN', ng=32, act=True):\n",
    "        super(Linear, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.linear = nn.Linear(n_in, n_out, bias=False)\n",
    "        \n",
    "        if norm == 'GN':\n",
    "            self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.norm(out)\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class LinearRes(nn.Module):\n",
    "    def __init__(self, n_in, n_out, norm='GN', ng=32):\n",
    "        super(LinearRes, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.linear1 = nn.Linear(n_in, n_out, bias=False)\n",
    "        self.linear2 = nn.Linear(n_out, n_out, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if norm == 'GN':\n",
    "            self.norm1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "            self.norm2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm1 = nn.BatchNorm1d(n_out)\n",
    "            self.norm2 = nn.BatchNorm1d(n_out)\n",
    "        else:   \n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        if n_in != n_out:\n",
    "            if norm == 'GN':\n",
    "                self.transform = nn.Sequential(\n",
    "                    nn.Linear(n_in, n_out, bias=False),\n",
    "                    nn.GroupNorm(gcd(ng, n_out), n_out))\n",
    "            elif norm == 'BN':\n",
    "                self.transform = nn.Sequential(\n",
    "                    nn.Linear(n_in, n_out, bias=False),\n",
    "                    nn.BatchNorm1d(n_out))\n",
    "            else:\n",
    "                exit('SyncBN has not been added!')\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.norm2(out)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            out += self.transform(x)\n",
    "            \n",
    "        else:\n",
    "            out += x\n",
    "        out = self.relu(out) \n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Conv1d(nn.Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, norm='GN', ng=32, act=True):\n",
    "        super(Conv1d, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.conv = nn.Conv1d(n_in, n_out, kernel_size=kernel_size, padding=(int(kernel_size) - 1) // 2, stride=stride, bias=False)\n",
    "\n",
    "        if norm == 'GN':\n",
    "            self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.norm(out)\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    " \n",
    "\n",
    "class Res1d(nn.Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, norm='GN', ng=32, act=True):\n",
    "        super(Res1d, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "        padding = (int(kernel_size) - 1) // 2\n",
    "        self.conv1 = nn.Conv1d(n_in, n_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.conv2 = nn.Conv1d(n_out, n_out, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        # All use name bn1 and bn2 to load imagenet pretrained weights\n",
    "        if norm == 'GN':\n",
    "            self.bn1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "            self.bn2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.bn1 = nn.BatchNorm1d(n_out)\n",
    "            self.bn2 = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        if stride != 1 or n_out != n_in:\n",
    "            if norm == 'GN':\n",
    "                self.downsample = nn.Sequential(\n",
    "                        nn.Conv1d(n_in, n_out, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.GroupNorm(gcd(ng, n_out), n_out))\n",
    "            elif norm == 'BN':\n",
    "                self.downsample = nn.Sequential(\n",
    "                        nn.Conv1d(n_in, n_out, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.BatchNorm1d(n_out))\n",
    "            else:\n",
    "                exit('SyncBN has not been added!')\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        out += x\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def actor_gather(actors: List[Tensor]) -> Tuple[Tensor, List[Tensor]]:\n",
    "    \"\"\"\n",
    "    actors is data['feat']\n",
    "     \n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = len(actors)\n",
    "    num_actors = [len(x) for x in actors]\n",
    "\n",
    "    actors = [torch.stack(x).transpose(1, 2) for x in actors]\n",
    "    actors = torch.cat(actors, 0)\n",
    "\n",
    "    actor_idcs = []\n",
    "    count = 0\n",
    "    for i in range(batch_size):\n",
    "        idcs = torch.arange(count, count + num_actors[i]).to(actors.device)\n",
    "        actor_idcs.append(idcs)\n",
    "        count += num_actors[i]\n",
    "    return actors, actor_idcs\n",
    "\n",
    "\n",
    "def graph_gather(graphs):\n",
    "    batch_size = len(graphs)\n",
    "    node_idcs = []\n",
    "    count = 0\n",
    "    counts = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        counts.append(count)\n",
    "        idcs = torch.arange(count, count + graphs[i][\"num_nodes\"])\n",
    "        node_idcs.append(idcs)\n",
    "        count = count + graphs[i][\"num_nodes\"]\n",
    "\n",
    "    graph = dict()\n",
    "    graph[\"idcs\"] = node_idcs\n",
    "    graph[\"ctrs\"] = [x[\"ctrs\"] for x in graphs]\n",
    "\n",
    "    graph['feats'] = torch.cat([x['feats'] for x in graphs], 0)\n",
    "\n",
    "    for k1 in [\"pre\", \"suc\"]:\n",
    "        graph[k1] = []\n",
    "        for i in range(len(graphs[0][\"pre\"])):\n",
    "            graph[k1].append(dict())\n",
    "            for k2 in [\"u\", \"v\"]:\n",
    "                graph[k1][i][k2] = torch.cat(\n",
    "                    [graphs[j][k1][i][k2] + counts[j] for j in range(batch_size)], 0\n",
    "                )\n",
    "\n",
    "    for k1 in [\"left\", \"right\"]:\n",
    "        graph[k1] = dict()\n",
    "        for k2 in [\"u\", \"v\"]:\n",
    "            temp = [graphs[i][k1][k2] + counts[i] for i in range(batch_size)]\n",
    "            temp = [\n",
    "                x if x.dim() > 0 else graph[\"pre\"][0][\"u\"].new().resize_(0)\n",
    "                for x in temp\n",
    "            ]\n",
    "            graph[k1][k2] = torch.cat(temp)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "\n",
    "class ActorNet(nn.Module):\n",
    "    def __init__(self,config) -> None:\n",
    "        super(ActorNet,self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_in = config['dim_feats'][config['type_feats']][0]\n",
    "        n_out = [32, 64, 128]\n",
    "        blocks = [Res1d, Res1d, Res1d]\n",
    "        num_blocks = [2, 2, 2]\n",
    "\n",
    "        groups = []\n",
    "\n",
    "        for i in range(len(num_blocks)):\n",
    "\n",
    "            group = []\n",
    "\n",
    "            if i == 0:\n",
    "                group.append(blocks[i](n_in, n_out[i], norm=norm, ng=ng))\n",
    "            else:\n",
    "                group.append(blocks[i](n_in, n_out[i], stride=2, norm=norm, ng=ng))\n",
    "\n",
    "            for j in range(1, num_blocks[i]):\n",
    "                group.append(blocks[i](n_out[i], n_out[i], norm=norm, ng=ng))\n",
    "            \n",
    "            groups.append(nn.Sequential(*group))\n",
    "            \n",
    "            n_in = n_out[i]\n",
    "\n",
    "        self.groups = nn.ModuleList(groups)\n",
    "\n",
    "        n = config['n_actornet']#128\n",
    "        \n",
    "        lateral = []\n",
    "        for i in range(len(n_out)):\n",
    "            lateral.append(Conv1d(n_out[i], n, norm=norm, ng=ng, act=False))\n",
    "        self.lateral = nn.ModuleList(lateral)\n",
    "\n",
    "        self.outlayer = Res1d(n, n, norm=norm, ng=ng)\n",
    "\n",
    "    def forward(self, actors: Tensor) -> Tensor:\n",
    "        #actors [batch_size,feature_dim(),time_step(11)]\n",
    "        \n",
    "        out = actors\n",
    "        pad = torch.ones(out.size(0),out.size(1),1)\n",
    "\n",
    "        out = torch.cat((pad,out),2)\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(len(self.groups)):\n",
    "            out = self.groups[i](out)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        out = self.lateral[-1](outputs[-1])\n",
    "\n",
    "        for i in range(len(outputs) - 2, -1, -1):\n",
    "\n",
    "            out = F.interpolate(out, scale_factor=2, mode=\"linear\", align_corners=False)\n",
    "            tmp = self.lateral[i](outputs[i])\n",
    "\n",
    "            # if out.shape != tmp.shape:\n",
    "            #     out = out[:,:,:tmp.shape[2]]\n",
    "\n",
    "            out += tmp\n",
    "        \n",
    "        out = self.outlayer(out)[:,:,-1]\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class MapNet(nn.Module):\n",
    "  \n",
    "    def __init__(self, config):\n",
    "        super(MapNet, self).__init__()\n",
    "        self.config = config\n",
    "        n_map = 128\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "        n_in = config['dim_feats'][config['type_feats']][1]\n",
    "\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Linear(n_in, n_map),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_map, n_map, norm=norm, ng=ng, act=False),\n",
    "        )\n",
    "        self.seg = nn.Sequential(\n",
    "            nn.Linear(n_in, n_map),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_map, n_map, norm=norm, ng=ng, act=False),\n",
    "        )\n",
    "\n",
    "        keys = [\"ctr\", \"norm\", \"ctr2\", \"left\", \"right\"]\n",
    "        for i in range(config[\"num_scales\"]):\n",
    "            keys.append(\"pre\" + str(i))\n",
    "            keys.append(\"suc\" + str(i))\n",
    "\n",
    "        fuse = dict()\n",
    "        for key in keys:\n",
    "            fuse[key] = []\n",
    "\n",
    "        for i in range(4):\n",
    "            for key in fuse:\n",
    "                if key in [\"norm\"]:\n",
    "                    fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
    "                elif key in [\"ctr2\"]:\n",
    "                    fuse[key].append(Linear(n_map, n_map, norm=norm, ng=ng, act=False))\n",
    "                else:\n",
    "                    fuse[key].append(nn.Linear(n_map, n_map, bias=False))\n",
    "\n",
    "        for key in fuse:\n",
    "            fuse[key] = nn.ModuleList(fuse[key])\n",
    "        self.fuse = nn.ModuleDict(fuse)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        if (\n",
    "            len(graph[\"feats\"]) == 0\n",
    "            or len(graph[\"pre\"][-1][\"u\"]) == 0\n",
    "            or len(graph[\"suc\"][-1][\"u\"]) == 0\n",
    "        ):\n",
    "            temp = graph[\"feats\"]\n",
    "            return (\n",
    "                temp.new().resize_(0),\n",
    "                [temp.new().long().resize_(0) for x in graph[\"node_idcs\"]],\n",
    "                temp.new().resize_(0),\n",
    "            )\n",
    "\n",
    "        ctrs = torch.cat(graph[\"ctrs\"], 0)\n",
    "        feat = self.input(ctrs)\n",
    "        feat += self.seg(graph[\"feats\"])\n",
    "        feat = self.relu(feat)\n",
    "\n",
    "        \"\"\"fuse map\"\"\"\n",
    "        res = feat\n",
    "        for i in range(len(self.fuse[\"ctr\"])):\n",
    "            temp = self.fuse[\"ctr\"][i](feat)\n",
    "            for key in self.fuse:\n",
    "                if key.startswith(\"pre\") or key.startswith(\"suc\"):\n",
    "                    k1 = key[:3]\n",
    "                    k2 = int(key[3:])\n",
    "                    temp.index_add_(\n",
    "                        0,\n",
    "                        graph[k1][k2][\"u\"],\n",
    "                        self.fuse[key][i](feat[graph[k1][k2][\"v\"]]),\n",
    "                    )\n",
    "\n",
    "            if len(graph[\"left\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"left\"][\"u\"],\n",
    "                    self.fuse[\"left\"][i](feat[graph[\"left\"][\"v\"]]),\n",
    "                )\n",
    "            if len(graph[\"right\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"right\"][\"u\"],\n",
    "                    self.fuse[\"right\"][i](feat[graph[\"right\"][\"v\"]]),\n",
    "                )\n",
    "\n",
    "            feat = self.fuse[\"norm\"][i](temp)\n",
    "            feat = self.relu(feat)\n",
    "\n",
    "            feat = self.fuse[\"ctr2\"][i](feat)\n",
    "            feat += res\n",
    "            feat = self.relu(feat)\n",
    "            res = feat\n",
    "\n",
    "        return feat\n",
    "\n",
    "\n",
    "class Att(nn.Module):\n",
    "    def __init__(self, n_agt: int, n_ctx: int, config) -> None:\n",
    "        super(Att, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "        n_in = config['dim_feats'][config['type_feats']][1]\n",
    "\n",
    "        self.dist = nn.Sequential(\n",
    "            nn.Linear(n_in, n_ctx),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_ctx, n_ctx, norm=norm, ng=ng),\n",
    "        )\n",
    "\n",
    "        self.query = Linear(n_agt, n_ctx, norm=norm, ng=ng)\n",
    "\n",
    "        self.ctx = nn.Sequential(\n",
    "            Linear(3 * n_ctx, n_agt, norm=norm, ng=ng),\n",
    "            nn.Linear(n_agt, n_agt, bias=False),\n",
    "        )\n",
    "\n",
    "        self.agt = nn.Linear(n_agt, n_agt, bias=False)\n",
    "        self.norm = nn.GroupNorm(gcd(ng, n_agt), n_agt)\n",
    "        self.linear = Linear(n_agt, n_agt, norm=norm, ng=ng, act=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, agts: Tensor, agt_idcs: List[Tensor], agt_ctrs: List[Tensor], ctx: Tensor, ctx_idcs: List[Tensor], ctx_ctrs: List[Tensor], dist_th: float) -> Tensor:\n",
    "        # feat, graph[\"idcs\"], graph[\"ctrs\"], actors, actor_idcs, actor_ctrs, config[\"actor2map_dist\"]      \n",
    "        res = agts\n",
    "        if len(ctx) == 0:\n",
    "            agts = self.agt(agts)\n",
    "            agts = self.relu(agts)\n",
    "            agts = self.linear(agts)\n",
    "            agts += res\n",
    "            agts = self.relu(agts)\n",
    "            return agts\n",
    "\n",
    "        batch_size = len(agt_idcs)\n",
    "        hi, wi = [], []\n",
    "        hi_count, wi_count = 0, 0\n",
    "        n_c = self.config['dim_feats'][self.config['type_feats']][1]\n",
    "\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "        \n",
    "            dist = agt_ctrs[i].view(-1, 1, n_c) - ctx_ctrs[i].view(1, -1, n_c)\n",
    "            dist = torch.sqrt((dist ** 2).sum(2))\n",
    "            mask = dist <= dist_th\n",
    "\n",
    "            idcs = torch.nonzero(mask, as_tuple=False)\n",
    "            if len(idcs) == 0:\n",
    "                continue\n",
    "\n",
    "            hi.append(idcs[:, 0] + hi_count)\n",
    "            wi.append(idcs[:, 1] + wi_count)\n",
    "            hi_count += len(agt_idcs[i])\n",
    "            wi_count += len(ctx_idcs[i])\n",
    "\n",
    "        if hi == []:\n",
    "            print('WARNING!!! - Attention')\n",
    "\n",
    "        hi = torch.cat(hi, 0)\n",
    "        wi = torch.cat(wi, 0)\n",
    "\n",
    "        agt_ctrs = torch.cat(agt_ctrs, 0)\n",
    "        ctx_ctrs = torch.cat(ctx_ctrs, 0)\n",
    "        dist = agt_ctrs[hi] - ctx_ctrs[wi]\n",
    "        dist = self.dist(dist)\n",
    "\n",
    "        query = self.query(agts[hi])\n",
    "\n",
    "        ctx = ctx[wi]\n",
    "        ctx = torch.cat((dist, query, ctx), 1)\n",
    "        ctx = self.ctx(ctx)\n",
    "\n",
    "        agts = self.agt(agts)\n",
    "        agts.index_add_(0, hi, ctx)\n",
    "        agts = self.norm(agts)\n",
    "        agts = self.relu(agts)\n",
    "\n",
    "        agts = self.linear(agts)\n",
    "        agts += res\n",
    "        agts = self.relu(agts)\n",
    "\n",
    "        return agts\n",
    "\n",
    "\n",
    "class A2M(nn.Module):\n",
    "    \"\"\"\n",
    "    Actor to Map Fusion:  fuses real-time traffic information from\n",
    "    actor nodes to lane nodes\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(A2M, self).__init__()\n",
    "        self.config = config\n",
    "        n_map = config[\"n_map\"]\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        \"\"\"fuse meta, static, dyn\"\"\"\n",
    "        self.meta = Linear(n_map, n_map, norm=norm, ng=ng)\n",
    "        att = []\n",
    "        for i in range(2):\n",
    "            att.append(Att(n_map, config[\"n_actor\"], config))\n",
    "        self.att = nn.ModuleList(att)\n",
    "\n",
    "    def forward(self, feat: Tensor, graph: Dict[str, Union[List[Tensor], Tensor, List[Dict[str, Tensor]], Dict[str, Tensor]]], actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor]) -> Tensor:\n",
    "        \"\"\"meta, static and dyn fuse using attention\"\"\"\n",
    "        \n",
    "        feat = self.meta(feat)\n",
    "\n",
    "        for i in range(len(self.att)):\n",
    "            feat = self.att[i](\n",
    "                feat,\n",
    "                graph[\"idcs\"],\n",
    "                graph[\"ctrs\"],\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                self.config[\"actor2map_dist\"],\n",
    "            )\n",
    "        return feat\n",
    "\n",
    "\n",
    "class M2M(nn.Module):\n",
    " \n",
    "    def __init__(self, config):\n",
    "        super(M2M, self).__init__()\n",
    "        self.config = config\n",
    "        n_map = config[\"n_map\"]\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        keys = [\"ctr\", \"norm\", \"ctr2\", \"left\", \"right\"]\n",
    "        for i in range(config[\"num_scales\"]):\n",
    "            keys.append(\"pre\" + str(i))\n",
    "            keys.append(\"suc\" + str(i))\n",
    "\n",
    "        fuse = dict()\n",
    "        for key in keys:\n",
    "            fuse[key] = []\n",
    "\n",
    "        for i in range(4):\n",
    "            for key in fuse:\n",
    "                if key in [\"norm\"]:\n",
    "                    fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
    "                elif key in [\"ctr2\"]:\n",
    "                    fuse[key].append(Linear(n_map, n_map, norm=norm, ng=ng, act=False))\n",
    "                else:\n",
    "                    fuse[key].append(nn.Linear(n_map, n_map, bias=False))\n",
    "\n",
    "        for key in fuse:\n",
    "            fuse[key] = nn.ModuleList(fuse[key])\n",
    "        self.fuse = nn.ModuleDict(fuse)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, feat: Tensor, graph: Dict) -> Tensor:\n",
    "        \"\"\"fuse map\"\"\"\n",
    "        res = feat\n",
    "        for i in range(len(self.fuse[\"ctr\"])):\n",
    "            temp = self.fuse[\"ctr\"][i](feat)\n",
    "            for key in self.fuse:\n",
    "                if key.startswith(\"pre\") or key.startswith(\"suc\"):\n",
    "                    k1 = key[:3]\n",
    "                    k2 = int(key[3:])\n",
    "                    temp.index_add_(\n",
    "                        0,\n",
    "                        graph[k1][k2][\"u\"],\n",
    "                        self.fuse[key][i](feat[graph[k1][k2][\"v\"]]),\n",
    "                    )\n",
    "\n",
    "            if len(graph[\"left\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"left\"][\"u\"],\n",
    "                    self.fuse[\"left\"][i](feat[graph[\"left\"][\"v\"]]),\n",
    "                )\n",
    "            if len(graph[\"right\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"right\"][\"u\"],\n",
    "                    self.fuse[\"right\"][i](feat[graph[\"right\"][\"v\"]]),\n",
    "                )\n",
    "\n",
    "            feat = self.fuse[\"norm\"][i](temp)\n",
    "            feat = self.relu(feat)\n",
    "\n",
    "            feat = self.fuse[\"ctr2\"][i](feat)\n",
    "            feat += res\n",
    "            feat = self.relu(feat)\n",
    "            res = feat\n",
    "        return feat\n",
    "\n",
    "\n",
    "# class M2A(nn.Module):\n",
    "#     \"\"\"\n",
    "#     The lane to actor block fuses updated\n",
    "#         map information from lane nodes to actor nodes\n",
    "#     \"\"\"\n",
    "#     def __init__(self, config):\n",
    "#         super(M2A, self).__init__()\n",
    "#         self.config = config\n",
    "#         norm = \"GN\"\n",
    "#         ng = 1\n",
    "\n",
    "#         n_actor = config[\"n_actor\"]\n",
    "#         n_map = config[\"n_map\"]\n",
    "\n",
    "#         att = []\n",
    "#         for i in range(2):\n",
    "#             att.append(Att(n_actor, n_map, config))\n",
    "#         self.att = nn.ModuleList(att)\n",
    "\n",
    "#     def forward(self, actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor], nodes: Tensor, node_idcs: List[Tensor], node_ctrs: List[Tensor]) -> Tensor:\n",
    "#         for i in range(len(self.att)):\n",
    "#             actors = self.att[i](\n",
    "#                 actors,\n",
    "#                 actor_idcs,\n",
    "#                 actor_ctrs,\n",
    "#                 nodes,\n",
    "#                 node_idcs,\n",
    "#                 node_ctrs,\n",
    "#                 self.config[\"map2actor_dist\"],\n",
    "#             )\n",
    "#         return actors\n",
    "\n",
    "\n",
    "class A2A(nn.Module):\n",
    "    \"\"\"\n",
    "    The actor to actor block performs interactions among actors.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(A2A, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_actor = config[\"n_actor\"]\n",
    "\n",
    "        att = []\n",
    "        for i in range(2):\n",
    "            att.append(Att(n_actor, n_actor, config))\n",
    "        self.att = nn.ModuleList(att)\n",
    "\n",
    "    def forward(self, actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor]) -> Tensor:\n",
    "        for i in range(len(self.att)):\n",
    "            actors = self.att[i](\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                self.config[\"actor2actor_dist\"],\n",
    "            )\n",
    "        return actors\n",
    "\n",
    "\n",
    "class PredNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(PredNet, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_actor = config[\"n_actor\"]\n",
    "\n",
    "        pred = []\n",
    "        for i in range(config[\"num_mods\"]):\n",
    "            pred.append(\n",
    "                nn.Sequential(\n",
    "                    LinearRes(n_actor, n_actor, norm=norm, ng=ng),\n",
    "                    nn.Linear(n_actor, 2 * config[\"num_preds\"]),\n",
    "                )\n",
    "            )\n",
    "        self.pred = nn.ModuleList(pred)\n",
    "\n",
    "        self.att_dest = AttDest(n_actor)\n",
    "        self.cls = nn.Sequential(\n",
    "            LinearRes(n_actor, n_actor, norm=norm, ng=ng), nn.Linear(n_actor, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor]) -> Dict[str, List[Tensor]]:\n",
    "        preds = []\n",
    "        for i in range(len(self.pred)):\n",
    "            preds.append(self.pred[i](actors))\n",
    "        reg = torch.cat([x.unsqueeze(1) for x in preds], 1)\n",
    "        reg = reg.view(reg.size(0), reg.size(1), -1, 2)\n",
    "\n",
    "        n_c = self.config['dim_feats'][self.config['type_feats']][1]\n",
    "        for i in range(len(actor_idcs)):\n",
    "            idcs = actor_idcs[i]\n",
    "            ctrs = actor_ctrs[i].view(-1, 1, 1, n_c)\n",
    "            reg[idcs] = reg[idcs] + ctrs[:,:,:,:2]\n",
    "\n",
    "        dest_ctrs = reg[:, :, -1].detach()\n",
    "        feats = self.att_dest(actors, torch.cat(actor_ctrs, 0), dest_ctrs)\n",
    "        cls = self.cls(feats).view(-1, self.config[\"num_mods\"])\n",
    "\n",
    "        cls, sort_idcs = cls.sort(1, descending=True)\n",
    "        row_idcs = torch.arange(len(sort_idcs)).long().to(sort_idcs.device)\n",
    "        row_idcs = row_idcs.view(-1, 1).repeat(1, sort_idcs.size(1)).view(-1)\n",
    "        sort_idcs = sort_idcs.view(-1)\n",
    "        reg = reg[row_idcs, sort_idcs].view(cls.size(0), cls.size(1), -1, 2)\n",
    "\n",
    "        out = dict()\n",
    "        out[\"cls\"], out[\"reg\"] = [], []\n",
    "        for i in range(len(actor_idcs)):\n",
    "            idcs = actor_idcs[i]\n",
    "            out[\"cls\"].append(cls[idcs])\n",
    "            out[\"reg\"].append(reg[idcs])\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttDest(nn.Module):\n",
    "    def __init__(self, n_agt: int):\n",
    "        super(AttDest, self).__init__()\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        self.dist = nn.Sequential(\n",
    "            nn.Linear(2, n_agt),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_agt, n_agt, norm=norm, ng=ng),\n",
    "        )\n",
    "\n",
    "        self.agt = Linear(2 * n_agt, n_agt, norm=norm, ng=ng)\n",
    "\n",
    "    def forward(self, agts: Tensor, agt_ctrs: Tensor, dest_ctrs: Tensor) -> Tensor:\n",
    "        n_agt = agts.size(1)\n",
    "        num_mods = dest_ctrs.size(1)\n",
    "\n",
    "        dist = (agt_ctrs[:,:2].unsqueeze(1) - dest_ctrs).view(-1, 2)\n",
    "        dist = self.dist(dist)\n",
    "        agts = agts.unsqueeze(1).repeat(1, num_mods, 1).view(-1, n_agt)\n",
    "\n",
    "        agts = torch.cat((dist, agts), 1)\n",
    "        agts = self.agt(agts)\n",
    "        return agts\n",
    "\n",
    "\n",
    "class GreatNet(nn.Module):\n",
    "    def __init__(self,config) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.actor_net = ActorNet(config)\n",
    "        self.map_net = MapNet(config)\n",
    "\n",
    "        self.a2m = A2M(config)\n",
    "        self.m2m = M2M(config)\n",
    "        self.m2a = M2A(config)\n",
    "        self.a2a = A2A(config)\n",
    "        \n",
    "        self.pred_net = PredNet(config)\n",
    "    \n",
    "    def forward(self, data: Dict) -> Tensor:\n",
    "\n",
    "        actors, actor_idcs = actor_gather(data[\"feats\"])\n",
    "        actor_ctrs = [torch.stack(i,0) for i in data[\"ctrs\"]]\n",
    "\n",
    "        actors = gpu(actors)\n",
    "        actor_idcs = gpu(actor_idcs)\n",
    "        actor_ctrs = gpu(actor_ctrs)\n",
    "\n",
    "        actors = self.actor_net(actors)\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        graph = to_long(data['graph'])\n",
    "        graph = graph_gather(graph)\n",
    "\n",
    "        graph = gpu(graph)\n",
    "\n",
    "        nodes, node_idcs, node_ctrs = self.map_net(graph)\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "        \n",
    "        nodes = self.a2m(nodes, graph, actors, actor_idcs, actor_ctrs)\n",
    "        nodes = self.m2m(nodes, graph)\n",
    "        actors = self.m2a(actors, actor_idcs, actor_ctrs, nodes, node_idcs, node_ctrs)\n",
    "        actors = self.a2a(actors, actor_idcs, actor_ctrs)\n",
    "        \n",
    "        out = self.pred_net(actors, actor_idcs, actor_ctrs)\n",
    "        rot, orig = gpu(data[\"rot\"]), gpu(data[\"orig\"])\n",
    "\n",
    "        # to_global\n",
    "        for i in range(len(out[\"reg\"])):\n",
    "            out[\"reg\"][i] = torch.matmul(out[\"reg\"][i], rot[i]) + orig[i][:2].view(1, 1, 1, -1)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class W_Dataset(Dataset):\n",
    "    def __init__(self,path) -> None:\n",
    "\n",
    "        self.path = path\n",
    "        self.files = os.listdir(path)\n",
    "    \n",
    "    def __getitem__(self, index) -> dict:\n",
    "\n",
    "        data_path = os.path.join(self.path,self.files[index])\n",
    "        data = torch.load(data_path)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dataset_train = W_Dataset(config['train_split'])\n",
    "train_loader = DataLoader(dataset_train, \n",
    "                        batch_size = batch_size ,\n",
    "                        collate_fn = collate_fn, \n",
    "                        shuffle = True, \n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "        if i > 0:\n",
    "            break\n",
    "        zz = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpAtt(nn.Module):\n",
    "    def __init__(self, n_agt: int, n_ctx: int, config) -> None:\n",
    "        super(SpAtt, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "        n_in = config['dim_feats'][config['type_feats']][1]\n",
    "\n",
    "        self.dist = nn.Sequential(\n",
    "            nn.Linear(n_in, n_ctx),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_ctx, n_ctx, norm=norm, ng=ng),\n",
    "        )\n",
    "\n",
    "        self.query = Linear(n_agt, n_ctx, norm=norm, ng=ng)\n",
    "\n",
    "        self.ctx = nn.Sequential(\n",
    "            Linear(3 * n_ctx, n_agt, norm=norm, ng=ng),\n",
    "            nn.Linear(n_agt, n_agt, bias=False),\n",
    "        )\n",
    "\n",
    "        self.agt = nn.Linear(n_agt, n_agt, bias=False)\n",
    "        self.norm = nn.GroupNorm(gcd(ng, n_agt), n_agt)\n",
    "        self.linear = Linear(n_agt, n_agt, norm=norm, ng=ng, act=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, agts: Tensor, agt_idcs: List[Tensor], agt_ctrs: List[Tensor], ctx: Tensor, ctx_idcs: List[Tensor], ctx_ctrs: List[Tensor], dist_th: float, graph: Dict) -> Tensor:\n",
    "        # ctx = nodes, agts = objects\n",
    "        # get the features of nodes(current, 6 sucs) into  objects\n",
    "        res = agts\n",
    "        if len(ctx) == 0:\n",
    "            agts = self.agt(agts)\n",
    "            agts = self.relu(agts)\n",
    "            agts = self.linear(agts)\n",
    "            agts += res\n",
    "            agts = self.relu(agts)\n",
    "            return agts\n",
    "\n",
    "        batch_size = len(agt_idcs)\n",
    "        hi, wi = [], []\n",
    "        hi_count, wi_count = 0, 0\n",
    "        n_c = self.config['dim_feats'][self.config['type_feats']][1]\n",
    "\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "\n",
    "            dist = agt_ctrs[i].view(-1, 1, n_c) - ctx_ctrs[i].view(1, -1, n_c)\n",
    "            dist = torch.sqrt((dist ** 2).sum(2))\n",
    "            mask = dist <= dist_th\n",
    "\n",
    "            idcs = torch.nonzero(mask, as_tuple=False)\n",
    "\n",
    "            if len(idcs) == 0:\n",
    "                continue\n",
    "\n",
    "            hi.append(idcs[:, 0] + hi_count)\n",
    "            wi.append(idcs[:, 1] + wi_count)\n",
    "            hi_count += len(agt_idcs[i])\n",
    "            wi_count += len(ctx_idcs[i])\n",
    "\n",
    "\n",
    "        hi = torch.cat(hi, 0)\n",
    "        wi = torch.cat(wi, 0)\n",
    "        agt_ctrs = torch.cat(agt_ctrs, 0)\n",
    "        ctx_ctrs = torch.cat(ctx_ctrs, 0)\n",
    "\n",
    "        # get the indx of all the sucs given wi\n",
    "        #(1) get the sparse matrix of (hi, wi)\n",
    "        #(2) have the sparse matrix of (wi, suc_i) in graph['suc']\n",
    "        #(3) get the sparse matrix of (hi, suc_i)\n",
    "\n",
    "        num_agts = len(agt_ctrs)\n",
    "        num_nodes = len(ctx_ctrs)\n",
    "\n",
    "        indcs = torch.stack((hi,wi))\n",
    "        value = torch.ones(len(hi))\n",
    "        size = torch.Size([num_agts, num_nodes])\n",
    "        sp_hw = torch.sparse_coo_tensor(indcs, value, size)\n",
    "        sp_final = sp_hw.clone()\n",
    "\n",
    "        for i in range(len(graph['suc'])):\n",
    "            u = graph['suc'][i]['u']\n",
    "            v = graph['suc'][i]['v']\n",
    "            indcs = torch.stack((u,v))\n",
    "            value = torch.ones(len(u))\n",
    "            size = torch.Size([num_nodes, num_nodes])\n",
    "            sp_uv = torch.sparse_coo_tensor(indcs, value, size)\n",
    "            sp_final += torch.matmul(sp_hw,sp_uv)\n",
    "\n",
    "        hi = sp_final.coalesce().indices()[0]\n",
    "        wi = sp_final.coalesce().indices()[1]\n",
    "\n",
    "        # conduct sparse spatial attention given (hi, suc_i)\n",
    "        dist = agt_ctrs[hi] - ctx_ctrs[wi]\n",
    "        dist = self.dist(dist)\n",
    "\n",
    "        query = self.query(agts[hi])\n",
    "\n",
    "        ctx = ctx[wi]\n",
    "        ctx = torch.cat((dist, query, ctx), 1)\n",
    "        ctx = self.ctx(ctx)\n",
    "\n",
    "        agts = self.agt(agts)\n",
    "        agts.index_add_(0, hi, ctx)\n",
    "        agts = self.norm(agts)\n",
    "        agts = self.relu(agts)\n",
    "\n",
    "        agts = self.linear(agts)\n",
    "        agts += res\n",
    "        agts = self.relu(agts)\n",
    "\n",
    "        return agts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2A(nn.Module):\n",
    "    \"\"\"\n",
    "    The lane to actor block fuses updated\n",
    "        map information from lane nodes to actor nodes\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(M2A, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_actor = config[\"n_actor\"]\n",
    "        n_map = config[\"n_map\"]\n",
    "\n",
    "        att = []\n",
    "        for i in range(2):\n",
    "            att.append(SpAtt(n_actor, n_map, config))\n",
    "        self.att = nn.ModuleList(att)\n",
    "\n",
    "    def forward(self, actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor], nodes: Tensor, graph: Dict) -> Tensor:\n",
    "        \n",
    "        node_idcs, node_ctrs = graph[\"idcs\"], graph[\"ctrs\"]\n",
    "        \n",
    "        for i in range(len(self.att)):\n",
    "            actors = self.att[i](\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                nodes,\n",
    "                node_idcs,\n",
    "                node_ctrs,\n",
    "                self.config[\"map2actor_dist\"],\n",
    "                graph\n",
    "            )\n",
    "            \n",
    "        return actors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net = ActorNet(config)\n",
    "map_net = MapNet(config)\n",
    "a2m = A2M(config)\n",
    "m2m = M2M(config)\n",
    "m2a = M2A(config)\n",
    "a2a = A2A(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors, actor_idcs = actor_gather(zz[\"feats\"])\n",
    "actor_ctrs = [torch.stack(i,0) for i in zz[\"ctrs\"]]\n",
    "\n",
    "actors = actor_net(actors)\n",
    "\n",
    "graph = to_long(zz['graph'])\n",
    "graph = graph_gather(graph)\n",
    "nodes = map_net(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = a2m(nodes, graph, actors, actor_idcs, actor_ctrs)\n",
    "nodes = m2m(nodes, graph)\n",
    "actors = m2a(actors, actor_idcs, actor_ctrs, nodes, graph)\n",
    "actors = a2a(actors, actor_idcs, actor_ctrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrs = torch.cat(graph['ctrs'],0)\n",
    "len(ctrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = torch.ones(4,6)\n",
    "pad = torch.zeros(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1,pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.concat([pad,u1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([pad,u1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = torch.tensor([0,1,1])\n",
    "u2 = torch.tensor([1,1,2])\n",
    "\n",
    "indcs = torch.stack((u1,u2))\n",
    "value = torch.ones(len(u1)).to(torch.bool)\n",
    "size = torch.Size([10,10])\n",
    "sm = torch.sparse_coo_tensor(indcs, value, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.coalesce().indices()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6517093863699129\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "random_float = random.uniform(0,2*np.pi)\n",
    "\n",
    "print(random_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 3)\n",
    "indices = torch.tensor([[1, 3, 2, 5], [4, 6, 9, 6]]) \n",
    "embedded = embedding(indices)\n",
    "embedded.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 2],\n",
       "        [4, 6, 9]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = torch.tensor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
