{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fractions import gcd\n",
    "from numbers import Number\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "from utils import to_long, gpu\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import collate_fn\n",
    "from net_M1 import pre_gather\n",
    "\n",
    "config = dict()\n",
    "config['n_actornet'] = 128\n",
    "config['num_epochs'] = 100\n",
    "config['lr'] = 1e-3\n",
    "config['train_split'] = '/home/avt/prediction/Waymo/data_processed/train'\n",
    "config['val_split'] = '/home/avt/prediction/Waymo/data_processed/validation'\n",
    "config[\"num_scales\"] = 6\n",
    "config[\"n_map\"] = 128\n",
    "config[\"n_actor\"] = 128\n",
    "config[\"actor2map_dist\"] = 7.0\n",
    "config[\"map2actor_dist\"] = 6.0\n",
    "config[\"actor2actor_dist\"] = 100.0\n",
    "config[\"num_mods\"] = 6\n",
    "config[\"pred_size\"] = 80\n",
    "config[\"pred_step\"] = 1\n",
    "config[\"num_preds\"] = config[\"pred_size\"] // config[\"pred_step\"]\n",
    "config[\"cls_th\"] = 2.0\n",
    "config[\"cls_ignore\"] = 0.2\n",
    "config[\"mgn\"] = 0.2\n",
    "config[\"cls_coef\"] = 1.0\n",
    "config[\"reg_coef\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W_Dataset(Dataset):\n",
    "    def __init__(self,path) -> None:\n",
    "\n",
    "        self.path = path\n",
    "        self.files = os.listdir(path)\n",
    "    \n",
    "    def __getitem__(self, index) -> dict:\n",
    "\n",
    "        data_path = os.path.join(self.path,self.files[index])\n",
    "        data = torch.load(data_path)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dataset_train = W_Dataset(config['train_split'])\n",
    "train_loader = DataLoader(dataset_train, \n",
    "                        batch_size = batch_size ,\n",
    "                        collate_fn = collate_fn, \n",
    "                        shuffle = True, \n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, data in enumerate(train_loader):\n",
    "    if batch_idx > 0:\n",
    "        break\n",
    "    zz = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,2,size =(4,3),dtype=torch.bool)\n",
    "z = torch.rand(4,3,2)\n",
    "a,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pre_gather(zz['gt2_preds'])\n",
    "hs = pre_gather(zz['has_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.size(), hs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt[hs].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.SmoothL1Loss(reduction = 'mean')\n",
    "loss1 = nn.MSELoss(reduction = 'sum')\n",
    "out = torch.ones((5,2))*2\n",
    "gt = torch.zeros((5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 2.],\n",
       "         [2., 2.],\n",
       "         [2., 2.],\n",
       "         [2., 2.],\n",
       "         [2., 2.]]),\n",
       " tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out,gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss1(out,gt)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
